{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0                       You Can Smell Hillary’s Fear   \n",
      "1  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2        Kerry to go to Paris in gesture of sympathy   \n",
      "3  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text  fake  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...     1  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...     1  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...     0  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...     1  \n",
      "4  It's primary day in New York and front-runners...     0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import warnings\n",
    "from langdetect import detect_langs\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('data/fake_or_real_news.csv')\n",
    "\n",
    "#替换列名\n",
    "df.rename(columns={\"label\":\"fake\"}, inplace=True)\n",
    "label_map = {\"FAKE\": 1, \"REAL\": 0}\n",
    "df['fake'] = df['fake'].map(label_map)\n",
    "\n",
    "#丢掉非英文的\n",
    "def return_lang(x):\n",
    "    try:\n",
    "        language = detect_langs(x)[0].lang\n",
    "    except Exception:\n",
    "        language = 'other'\n",
    "    return language\n",
    "df['language'] = df['text'].apply(return_lang)\n",
    "\n",
    "\n",
    "df = df[df['language']=='en']\n",
    "\n",
    "#丢掉无用的列\n",
    "df = df.drop(['Unnamed: 0','title_vectors','language'],axis=1)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def splitSentence(paragraph):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = tokenizer.tokenize(paragraph)\n",
    "    return sentences\n",
    "\n",
    "def divide_text1(x):\n",
    "    text = x['text']\n",
    "    temp = splitSentence(text)\n",
    "    text1=\"\"\n",
    "    for i in range(int(len(temp)/2)):\n",
    "        text1=text1+temp[i]+\" \"\n",
    "    return text1\n",
    "def divide_text2(x):\n",
    "    text = x['text']\n",
    "    temp = splitSentence(text)\n",
    "    text2=\"\"\n",
    "    for i in range(int(len(temp)/2),len(temp)):\n",
    "        text2=text2+temp[i]+\" \"\n",
    "    return text2\n",
    "df['text1'] = df.apply(divide_text1,axis=1)\n",
    "df['text2'] = df.apply(divide_text2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>fake</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>1</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>Going to war with the FBI is not the behavior ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>1</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>If Ryan’s career manages to limp all the way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>0</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>The highest ranking U.S. officials attending t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>1</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>Democrats nominated the only damn candidate wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>0</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>Trump needs to capture more than 50 percent of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>1</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>Often, I discovered, those same bullies could ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>“I was scared, because they were saying I’m go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>0</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>Though the children were originally set to arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>Trump referred to the fact that Cuba’s preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>0</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>A senior U.S. official characterized the issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>With all three Clintons in Iowa, a glimpse at ...</td>\n",
       "      <td>CEDAR RAPIDS, Iowa — “I had one of the most wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>CEDAR RAPIDS, Iowa — “I had one of the most wo...</td>\n",
       "      <td>Clinton, who seemed to draw on the higher-than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Donald Trump’s Shockingly Weak Delegate Game S...</td>\n",
       "      <td>Donald Trump’s organizational problems have go...</td>\n",
       "      <td>0</td>\n",
       "      <td>Donald Trump’s organizational problems have go...</td>\n",
       "      <td>This past weekend’s mix-up, though, was an eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Strong Solar Storm, Tech Risks Today | S0 News...</td>\n",
       "      <td>Click Here To Learn More About Alexandra's Per...</td>\n",
       "      <td>1</td>\n",
       "      <td>Click Here To Learn More About Alexandra's Per...</td>\n",
       "      <td>Privacy Policy \\nBy subscribing to GalacticCon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10 Ways America Is Preparing for World War 3</td>\n",
       "      <td>October 31, 2016 at 4:52 am \\nPretty factual e...</td>\n",
       "      <td>1</td>\n",
       "      <td>October 31, 2016 at 4:52 am \\nPretty factual e...</td>\n",
       "      <td>American military is still voluntary only and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Trump takes on Cruz, but lightly</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How women lead differently</td>\n",
       "      <td>As more women move into high offices, they oft...</td>\n",
       "      <td>0</td>\n",
       "      <td>As more women move into high offices, they oft...</td>\n",
       "      <td>But that becomes a Catch-22: Women don’t step ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shocking! Michele Obama &amp; Hillary Caught Glamo...</td>\n",
       "      <td>Shocking! Michele Obama &amp; Hillary Caught Glamo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Shocking! Michele Obama &amp; Hillary Caught Glamo...</td>\n",
       "      <td>Rappers who have been welcomed to the White Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hillary Clinton in HUGE Trouble After America ...</td>\n",
       "      <td>0 \\nHillary Clinton has barely just lost the p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0 \\nHillary Clinton has barely just lost the p...</td>\n",
       "      <td>That’s actually where the older picture was ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What's in that Iran bill that Obama doesn't like?</td>\n",
       "      <td>Washington (CNN) For months, the White House a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Washington (CNN) For months, the White House a...</td>\n",
       "      <td>The biggest sanctions package approved by Cong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The 1 chart that explains everything you need ...</td>\n",
       "      <td>While paging through Pew's best data visualiza...</td>\n",
       "      <td>0</td>\n",
       "      <td>While paging through Pew's best data visualiza...</td>\n",
       "      <td>To me, this chart is so important -- particula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The slippery slope to Trump’s proposed ban on ...</td>\n",
       "      <td>With little fanfare this fall, the New York de...</td>\n",
       "      <td>0</td>\n",
       "      <td>With little fanfare this fall, the New York de...</td>\n",
       "      <td>The demagoguery began with the labeling of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Episode #160 – SUNDAY WIRE: ‘Hail to the Deplo...</td>\n",
       "      <td>November 13, 2016 By 21wire Leave a Comment \\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>November 13, 2016 By 21wire Leave a Comment \\n...</td>\n",
       "      <td>In the first hour we’ll conduct a post-mortem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hillary Clinton Makes A Bipartisan Appeal on S...</td>\n",
       "      <td>Hillary Clinton told a Staten Island crowd tod...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hillary Clinton told a Staten Island crowd tod...</td>\n",
       "      <td>“I publicly say, ‘Thank you President George W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New Senate majority leader’s main goal for GOP...</td>\n",
       "      <td>Mitch McConnell has an unusual admonition for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mitch McConnell has an unusual admonition for ...</td>\n",
       "      <td>Obama has issued only two minor vetoes over te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>‘Inferno’ and the Overpopulation Myth</td>\n",
       "      <td>Mises.org November 1, 2016 Inferno is a great ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mises.org November 1, 2016 Inferno is a great ...</td>\n",
       "      <td>Are we at risk of running out of food, medicin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Anti-Trump forces seek last-ditch delegate revolt</td>\n",
       "      <td>Washington (CNN) The faction of the GOP that i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Washington (CNN) The faction of the GOP that i...</td>\n",
       "      <td>He tried but failed to get the party to adopt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sanders Trounces Clinton in W. Va. -- But Will...</td>\n",
       "      <td>Meanwhile, Democrat Bernie Sanders picked up m...</td>\n",
       "      <td>0</td>\n",
       "      <td>Meanwhile, Democrat Bernie Sanders picked up m...</td>\n",
       "      <td>She's also polling badly among whites, men, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Donald Trump Is Changing His Campaign Slogan t...</td>\n",
       "      <td>After a week of nonstop criticism from Democra...</td>\n",
       "      <td>0</td>\n",
       "      <td>After a week of nonstop criticism from Democra...</td>\n",
       "      <td>It’s true.”\\n\\nThe allegedly amended slogan, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pure chaos: Donald Trump’s campaign management...</td>\n",
       "      <td>If you want a glimpse into a presidential cand...</td>\n",
       "      <td>0</td>\n",
       "      <td>If you want a glimpse into a presidential cand...</td>\n",
       "      <td>Based on the latest behind-the-scenes reports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Syrian War Report – November 1, 2016: Syrian M...</td>\n",
       "      <td>Syrian War Report – October 31, 2016: Al-Nusra...</td>\n",
       "      <td>1</td>\n",
       "      <td>Syrian War Report – October 31, 2016: Al-Nusra...</td>\n",
       "      <td>The Kurdish YPG and the Ankara-led forces (Tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304</th>\n",
       "      <td>Obama Furious After Fed-Up ‘Deplorables’ Drop ...</td>\n",
       "      <td>Obama Furious After Fed-Up ‘Deplorables’ Drop ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Obama Furious After Fed-Up ‘Deplorables’ Drop ...</td>\n",
       "      <td>While Hillary has everyone from the mainstream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6305</th>\n",
       "      <td>Colin Kaepernick hosts ‘Know Your Rights’ camp...</td>\n",
       "      <td>Print \\n[Ed. – Now teaching the gospel of raci...</td>\n",
       "      <td>1</td>\n",
       "      <td>Print \\n[Ed. – Now teaching the gospel of raci...</td>\n",
       "      <td>Kaepernick said the campers, who numbered arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>Wikileaks Emails Disclose Aliens Linked to Vat...</td>\n",
       "      <td>Sound too “strange” to be true? We have proof!...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sound too “strange” to be true? We have proof!...</td>\n",
       "      <td>In the video below, the famous author, pastor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>US abstains from UN vote calling for end to Cu...</td>\n",
       "      <td>US abstains from UN vote calling for end to Cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>US abstains from UN vote calling for end to Cu...</td>\n",
       "      <td>When it was first announced that the US govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>West Ham fans laud aerodynamic properties of n...</td>\n",
       "      <td>Tuesday 1 November 2016 by Formelia Alberthine...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday 1 November 2016 by Formelia Alberthine...</td>\n",
       "      <td>“They’re quite weighty – I had become accustom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>How the Obama White House runs foreign policy</td>\n",
       "      <td>When Susan E. Rice took over as President Obam...</td>\n",
       "      <td>0</td>\n",
       "      <td>When Susan E. Rice took over as President Obam...</td>\n",
       "      <td>Established in the years following World War I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6310</th>\n",
       "      <td>ISIS claims responsibility for Garland, Texas,...</td>\n",
       "      <td>(CNN) ISIS has claimed responsibility for the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>(CNN) ISIS has claimed responsibility for the ...</td>\n",
       "      <td>2 of our brothers just opened fire.\" Both Twit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311</th>\n",
       "      <td>The “blame the left” crew: What the right’s ne...</td>\n",
       "      <td>It was inevitable that liberals would end up b...</td>\n",
       "      <td>0</td>\n",
       "      <td>It was inevitable that liberals would end up b...</td>\n",
       "      <td>After all, the shoe was on their religious fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>ADHD NATION: How Big Pharma Created the ADHD E...</td>\n",
       "      <td>By Kalee Brown\\nWhile I was at university, man...</td>\n",
       "      <td>1</td>\n",
       "      <td>By Kalee Brown\\nWhile I was at university, man...</td>\n",
       "      <td>You can’t just blame all doctors, either; many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6313</th>\n",
       "      <td>Donald Trump claims the election will be 'rigg...</td>\n",
       "      <td>Email \\nDonald Trump is again riling up his vo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Email \\nDonald Trump is again riling up his vo...</td>\n",
       "      <td>Jeanne Shaheen, a Democrat, and Republican US ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6314</th>\n",
       "      <td>REPORT: Dirty Reporter Blackmails Montel… Help...</td>\n",
       "      <td>BREAKING: Trump Jumps in FL, Takes 4 Point Lea...</td>\n",
       "      <td>1</td>\n",
       "      <td>BREAKING: Trump Jumps in FL, Takes 4 Point Lea...</td>\n",
       "      <td>It’s simply common decency. The Washington Exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>Police Arrest Suspect In Charleston Church Sho...</td>\n",
       "      <td>Police in Charleston, S.C., say a man they sus...</td>\n",
       "      <td>0</td>\n",
       "      <td>Police in Charleston, S.C., say a man they sus...</td>\n",
       "      <td>ET. Barbaric Crime:\\n\\n\"Acts like this one hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6316</th>\n",
       "      <td>Donald Trump’s collapse was caused by one big ...</td>\n",
       "      <td>Silver of FiveThirtyEight.com has laid out fou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Silver of FiveThirtyEight.com has laid out fou...</td>\n",
       "      <td>but not a crazy long shot. So what’s happening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>FINA suspends Russian swimmer for 8 years over...</td>\n",
       "      <td>This post was originally published on this sit...</td>\n",
       "      <td>1</td>\n",
       "      <td>This post was originally published on this sit...</td>\n",
       "      <td>The International Swimming Federation (FINA) h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6318</th>\n",
       "      <td>BREAKING : Hillary Campaign Manager Deletes hi...</td>\n",
       "      <td>BREAKING : Hillary Campaign Manager Deletes hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>BREAKING : Hillary Campaign Manager Deletes hi...</td>\n",
       "      <td>Join the resistance and help us fight to put A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>Why Ted Cruz Has the Most to Lose in New Hamps...</td>\n",
       "      <td>Ted Cruz took first prize in the Iowa caucuses...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ted Cruz took first prize in the Iowa caucuses...</td>\n",
       "      <td>Winning Iowa at all costs has also put a targe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6320</th>\n",
       "      <td>“Nothing Good Can Come of This Election”–and T...</td>\n",
       "      <td>Posted on November 4, 2016 by Charles Hugh Smi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Posted on November 4, 2016 by Charles Hugh Smi...</td>\n",
       "      <td>Nothing will change until the collusion of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>List of Republicans opposing Trump | OffGuardian</td>\n",
       "      <td>Charlie Baker , Massachusetts (2015–present)[3...</td>\n",
       "      <td>1</td>\n",
       "      <td>Charlie Baker , Massachusetts (2015–present)[3...</td>\n",
       "      <td>Gross , U.S. Coordinator for International Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6322</th>\n",
       "      <td>Putin: Use of 'mythical' Russian military thre...</td>\n",
       "      <td>vladimir putin , Valdai , sochi , RBTH Daily R...</td>\n",
       "      <td>1</td>\n",
       "      <td>vladimir putin , Valdai , sochi , RBTH Daily R...</td>\n",
       "      <td>\"Fabricated, mythical threats like the so-call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>Bernie Sanders says private meeting with Pope ...</td>\n",
       "      <td>ROME —  U.S. Democratic presidential candidate...</td>\n",
       "      <td>0</td>\n",
       "      <td>ROME —  U.S. Democratic presidential candidate...</td>\n",
       "      <td>\"The speech that I gave yesterday would have b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6324</th>\n",
       "      <td>Alabama Lawmaker: Same-Sex Couples Don’t Deser...</td>\n",
       "      <td>Most conservatives who oppose marriage equalit...</td>\n",
       "      <td>0</td>\n",
       "      <td>Most conservatives who oppose marriage equalit...</td>\n",
       "      <td>They found that if all states were to legalize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>Will the Media Reset After the Election or Are...</td>\n",
       "      <td>Written by Peter Van Buren   venerable New Yor...</td>\n",
       "      <td>1</td>\n",
       "      <td>Written by Peter Van Buren   venerable New Yor...</td>\n",
       "      <td>Who cares! Questions about what her accomplish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6326</th>\n",
       "      <td>DOJ COMPLAINT: Comey Under Fire Over Partisan ...</td>\n",
       "      <td>DOJ COMPLAINT: Comey Under Fire Over Partisan ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DOJ COMPLAINT: Comey Under Fire Over Partisan ...</td>\n",
       "      <td>The Associated Press tweeted: BREAKING: US off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>GOP Senator David Perdue Jokes About Praying f...</td>\n",
       "      <td>The freshman senator from Georgia quoted scrip...</td>\n",
       "      <td>0</td>\n",
       "      <td>The freshman senator from Georgia quoted scrip...</td>\n",
       "      <td>Adam Jentleson, a spokesman for Senate Minorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>Assange claims ‘crazed’ Clinton campaign tried...</td>\n",
       "      <td>Julian Assange has claimed the Hillary Clinton...</td>\n",
       "      <td>1</td>\n",
       "      <td>Julian Assange has claimed the Hillary Clinton...</td>\n",
       "      <td>Ecuador’s decision to shut down his internet w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>Clinton's campaign officials declined to comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>With further commentary from a handful of most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>The Oligarchy intends to delegitimize the Trum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>Obama is the first sitting U.S. president to v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>They're sleeping!\" Trump said to applause. Sin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6295 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                          You Can Smell Hillary’s Fear   \n",
       "1     Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           Kerry to go to Paris in gesture of sympathy   \n",
       "3     Bernie supporters on Twitter erupt in anger ag...   \n",
       "4      The Battle of New York: Why This Primary Matters   \n",
       "5                                           Tehran, USA   \n",
       "6     Girl Horrified At What She Watches Boyfriend D...   \n",
       "7                     ‘Britain’s Schindler’ Dies at 106   \n",
       "8     Fact check: Trump and Clinton at the 'commande...   \n",
       "9     Iran reportedly makes new push for uranium con...   \n",
       "10    With all three Clintons in Iowa, a glimpse at ...   \n",
       "11    Donald Trump’s Shockingly Weak Delegate Game S...   \n",
       "12    Strong Solar Storm, Tech Risks Today | S0 News...   \n",
       "13         10 Ways America Is Preparing for World War 3   \n",
       "14                     Trump takes on Cruz, but lightly   \n",
       "15                           How women lead differently   \n",
       "16    Shocking! Michele Obama & Hillary Caught Glamo...   \n",
       "17    Hillary Clinton in HUGE Trouble After America ...   \n",
       "18    What's in that Iran bill that Obama doesn't like?   \n",
       "19    The 1 chart that explains everything you need ...   \n",
       "20    The slippery slope to Trump’s proposed ban on ...   \n",
       "21    Episode #160 – SUNDAY WIRE: ‘Hail to the Deplo...   \n",
       "22    Hillary Clinton Makes A Bipartisan Appeal on S...   \n",
       "23    New Senate majority leader’s main goal for GOP...   \n",
       "24                ‘Inferno’ and the Overpopulation Myth   \n",
       "25    Anti-Trump forces seek last-ditch delegate revolt   \n",
       "26    Sanders Trounces Clinton in W. Va. -- But Will...   \n",
       "27    Donald Trump Is Changing His Campaign Slogan t...   \n",
       "28    Pure chaos: Donald Trump’s campaign management...   \n",
       "29    Syrian War Report – November 1, 2016: Syrian M...   \n",
       "...                                                 ...   \n",
       "6304  Obama Furious After Fed-Up ‘Deplorables’ Drop ...   \n",
       "6305  Colin Kaepernick hosts ‘Know Your Rights’ camp...   \n",
       "6306  Wikileaks Emails Disclose Aliens Linked to Vat...   \n",
       "6307  US abstains from UN vote calling for end to Cu...   \n",
       "6308  West Ham fans laud aerodynamic properties of n...   \n",
       "6309      How the Obama White House runs foreign policy   \n",
       "6310  ISIS claims responsibility for Garland, Texas,...   \n",
       "6311  The “blame the left” crew: What the right’s ne...   \n",
       "6312  ADHD NATION: How Big Pharma Created the ADHD E...   \n",
       "6313  Donald Trump claims the election will be 'rigg...   \n",
       "6314  REPORT: Dirty Reporter Blackmails Montel… Help...   \n",
       "6315  Police Arrest Suspect In Charleston Church Sho...   \n",
       "6316  Donald Trump’s collapse was caused by one big ...   \n",
       "6317  FINA suspends Russian swimmer for 8 years over...   \n",
       "6318  BREAKING : Hillary Campaign Manager Deletes hi...   \n",
       "6319  Why Ted Cruz Has the Most to Lose in New Hamps...   \n",
       "6320  “Nothing Good Can Come of This Election”–and T...   \n",
       "6321   List of Republicans opposing Trump | OffGuardian   \n",
       "6322  Putin: Use of 'mythical' Russian military thre...   \n",
       "6323  Bernie Sanders says private meeting with Pope ...   \n",
       "6324  Alabama Lawmaker: Same-Sex Couples Don’t Deser...   \n",
       "6325  Will the Media Reset After the Election or Are...   \n",
       "6326  DOJ COMPLAINT: Comey Under Fire Over Partisan ...   \n",
       "6327  GOP Senator David Perdue Jokes About Praying f...   \n",
       "6329  Assange claims ‘crazed’ Clinton campaign tried...   \n",
       "6330  State Department says it can't find emails fro...   \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text  fake  \\\n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...     1   \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...     1   \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...     0   \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...     1   \n",
       "4     It's primary day in New York and front-runners...     0   \n",
       "5       \\nI’m not an immigrant, but my grandparents ...     1   \n",
       "6     Share This Baylee Luciani (left), Screenshot o...     1   \n",
       "7     A Czech stockbroker who saved more than 650 Je...     0   \n",
       "8     Hillary Clinton and Donald Trump made some ina...     0   \n",
       "9     Iranian negotiators reportedly have made a las...     0   \n",
       "10    CEDAR RAPIDS, Iowa — “I had one of the most wo...     0   \n",
       "11    Donald Trump’s organizational problems have go...     0   \n",
       "12    Click Here To Learn More About Alexandra's Per...     1   \n",
       "13    October 31, 2016 at 4:52 am \\nPretty factual e...     1   \n",
       "14    Killing Obama administration rules, dismantlin...     0   \n",
       "15    As more women move into high offices, they oft...     0   \n",
       "16    Shocking! Michele Obama & Hillary Caught Glamo...     1   \n",
       "17    0 \\nHillary Clinton has barely just lost the p...     1   \n",
       "18    Washington (CNN) For months, the White House a...     0   \n",
       "19    While paging through Pew's best data visualiza...     0   \n",
       "20    With little fanfare this fall, the New York de...     0   \n",
       "21    November 13, 2016 By 21wire Leave a Comment \\n...     1   \n",
       "22    Hillary Clinton told a Staten Island crowd tod...     0   \n",
       "23    Mitch McConnell has an unusual admonition for ...     0   \n",
       "24    Mises.org November 1, 2016 Inferno is a great ...     1   \n",
       "25    Washington (CNN) The faction of the GOP that i...     0   \n",
       "26    Meanwhile, Democrat Bernie Sanders picked up m...     0   \n",
       "27    After a week of nonstop criticism from Democra...     0   \n",
       "28    If you want a glimpse into a presidential cand...     0   \n",
       "29    Syrian War Report – October 31, 2016: Al-Nusra...     1   \n",
       "...                                                 ...   ...   \n",
       "6304  Obama Furious After Fed-Up ‘Deplorables’ Drop ...     1   \n",
       "6305  Print \\n[Ed. – Now teaching the gospel of raci...     1   \n",
       "6306  Sound too “strange” to be true? We have proof!...     1   \n",
       "6307  US abstains from UN vote calling for end to Cu...     1   \n",
       "6308  Tuesday 1 November 2016 by Formelia Alberthine...     1   \n",
       "6309  When Susan E. Rice took over as President Obam...     0   \n",
       "6310  (CNN) ISIS has claimed responsibility for the ...     0   \n",
       "6311  It was inevitable that liberals would end up b...     0   \n",
       "6312  By Kalee Brown\\nWhile I was at university, man...     1   \n",
       "6313  Email \\nDonald Trump is again riling up his vo...     1   \n",
       "6314  BREAKING: Trump Jumps in FL, Takes 4 Point Lea...     1   \n",
       "6315  Police in Charleston, S.C., say a man they sus...     0   \n",
       "6316  Silver of FiveThirtyEight.com has laid out fou...     0   \n",
       "6317  This post was originally published on this sit...     1   \n",
       "6318  BREAKING : Hillary Campaign Manager Deletes hi...     1   \n",
       "6319  Ted Cruz took first prize in the Iowa caucuses...     0   \n",
       "6320  Posted on November 4, 2016 by Charles Hugh Smi...     1   \n",
       "6321  Charlie Baker , Massachusetts (2015–present)[3...     1   \n",
       "6322  vladimir putin , Valdai , sochi , RBTH Daily R...     1   \n",
       "6323  ROME —  U.S. Democratic presidential candidate...     0   \n",
       "6324  Most conservatives who oppose marriage equalit...     0   \n",
       "6325  Written by Peter Van Buren   venerable New Yor...     1   \n",
       "6326  DOJ COMPLAINT: Comey Under Fire Over Partisan ...     1   \n",
       "6327  The freshman senator from Georgia quoted scrip...     0   \n",
       "6329  Julian Assange has claimed the Hillary Clinton...     1   \n",
       "6330  The State Department told the Republican Natio...     0   \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...     1   \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...     1   \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...     0   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...     0   \n",
       "\n",
       "                                                  text1  \\\n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...   \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...   \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...   \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...   \n",
       "4     It's primary day in New York and front-runners...   \n",
       "5       \\nI’m not an immigrant, but my grandparents ...   \n",
       "6     Share This Baylee Luciani (left), Screenshot o...   \n",
       "7     A Czech stockbroker who saved more than 650 Je...   \n",
       "8     Hillary Clinton and Donald Trump made some ina...   \n",
       "9     Iranian negotiators reportedly have made a las...   \n",
       "10    CEDAR RAPIDS, Iowa — “I had one of the most wo...   \n",
       "11    Donald Trump’s organizational problems have go...   \n",
       "12    Click Here To Learn More About Alexandra's Per...   \n",
       "13    October 31, 2016 at 4:52 am \\nPretty factual e...   \n",
       "14                                                        \n",
       "15    As more women move into high offices, they oft...   \n",
       "16    Shocking! Michele Obama & Hillary Caught Glamo...   \n",
       "17    0 \\nHillary Clinton has barely just lost the p...   \n",
       "18    Washington (CNN) For months, the White House a...   \n",
       "19    While paging through Pew's best data visualiza...   \n",
       "20    With little fanfare this fall, the New York de...   \n",
       "21    November 13, 2016 By 21wire Leave a Comment \\n...   \n",
       "22    Hillary Clinton told a Staten Island crowd tod...   \n",
       "23    Mitch McConnell has an unusual admonition for ...   \n",
       "24    Mises.org November 1, 2016 Inferno is a great ...   \n",
       "25    Washington (CNN) The faction of the GOP that i...   \n",
       "26    Meanwhile, Democrat Bernie Sanders picked up m...   \n",
       "27    After a week of nonstop criticism from Democra...   \n",
       "28    If you want a glimpse into a presidential cand...   \n",
       "29    Syrian War Report – October 31, 2016: Al-Nusra...   \n",
       "...                                                 ...   \n",
       "6304  Obama Furious After Fed-Up ‘Deplorables’ Drop ...   \n",
       "6305  Print \\n[Ed. – Now teaching the gospel of raci...   \n",
       "6306  Sound too “strange” to be true? We have proof!...   \n",
       "6307  US abstains from UN vote calling for end to Cu...   \n",
       "6308  Tuesday 1 November 2016 by Formelia Alberthine...   \n",
       "6309  When Susan E. Rice took over as President Obam...   \n",
       "6310  (CNN) ISIS has claimed responsibility for the ...   \n",
       "6311  It was inevitable that liberals would end up b...   \n",
       "6312  By Kalee Brown\\nWhile I was at university, man...   \n",
       "6313  Email \\nDonald Trump is again riling up his vo...   \n",
       "6314  BREAKING: Trump Jumps in FL, Takes 4 Point Lea...   \n",
       "6315  Police in Charleston, S.C., say a man they sus...   \n",
       "6316  Silver of FiveThirtyEight.com has laid out fou...   \n",
       "6317  This post was originally published on this sit...   \n",
       "6318  BREAKING : Hillary Campaign Manager Deletes hi...   \n",
       "6319  Ted Cruz took first prize in the Iowa caucuses...   \n",
       "6320  Posted on November 4, 2016 by Charles Hugh Smi...   \n",
       "6321  Charlie Baker , Massachusetts (2015–present)[3...   \n",
       "6322  vladimir putin , Valdai , sochi , RBTH Daily R...   \n",
       "6323  ROME —  U.S. Democratic presidential candidate...   \n",
       "6324  Most conservatives who oppose marriage equalit...   \n",
       "6325  Written by Peter Van Buren   venerable New Yor...   \n",
       "6326  DOJ COMPLAINT: Comey Under Fire Over Partisan ...   \n",
       "6327  The freshman senator from Georgia quoted scrip...   \n",
       "6329  Julian Assange has claimed the Hillary Clinton...   \n",
       "6330  The State Department told the Republican Natio...   \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...   \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                  text2  \n",
       "0     Going to war with the FBI is not the behavior ...  \n",
       "1     If Ryan’s career manages to limp all the way t...  \n",
       "2     The highest ranking U.S. officials attending t...  \n",
       "3     Democrats nominated the only damn candidate wh...  \n",
       "4     Trump needs to capture more than 50 percent of...  \n",
       "5     Often, I discovered, those same bullies could ...  \n",
       "6     “I was scared, because they were saying I’m go...  \n",
       "7     Though the children were originally set to arr...  \n",
       "8     Trump referred to the fact that Cuba’s preside...  \n",
       "9     A senior U.S. official characterized the issue...  \n",
       "10    Clinton, who seemed to draw on the higher-than...  \n",
       "11    This past weekend’s mix-up, though, was an eve...  \n",
       "12    Privacy Policy \\nBy subscribing to GalacticCon...  \n",
       "13    American military is still voluntary only and ...  \n",
       "14    Killing Obama administration rules, dismantlin...  \n",
       "15    But that becomes a Catch-22: Women don’t step ...  \n",
       "16    Rappers who have been welcomed to the White Ho...  \n",
       "17    That’s actually where the older picture was ta...  \n",
       "18    The biggest sanctions package approved by Cong...  \n",
       "19    To me, this chart is so important -- particula...  \n",
       "20    The demagoguery began with the labeling of the...  \n",
       "21    In the first hour we’ll conduct a post-mortem ...  \n",
       "22    “I publicly say, ‘Thank you President George W...  \n",
       "23    Obama has issued only two minor vetoes over te...  \n",
       "24    Are we at risk of running out of food, medicin...  \n",
       "25    He tried but failed to get the party to adopt ...  \n",
       "26    She's also polling badly among whites, men, an...  \n",
       "27    It’s true.”\\n\\nThe allegedly amended slogan, w...  \n",
       "28    Based on the latest behind-the-scenes reports ...  \n",
       "29    The Kurdish YPG and the Ankara-led forces (Tur...  \n",
       "...                                                 ...  \n",
       "6304  While Hillary has everyone from the mainstream...  \n",
       "6305  Kaepernick said the campers, who numbered arou...  \n",
       "6306  In the video below, the famous author, pastor ...  \n",
       "6307  When it was first announced that the US govern...  \n",
       "6308  “They’re quite weighty – I had become accustom...  \n",
       "6309  Established in the years following World War I...  \n",
       "6310  2 of our brothers just opened fire.\" Both Twit...  \n",
       "6311  After all, the shoe was on their religious fee...  \n",
       "6312  You can’t just blame all doctors, either; many...  \n",
       "6313  Jeanne Shaheen, a Democrat, and Republican US ...  \n",
       "6314  It’s simply common decency. The Washington Exa...  \n",
       "6315  ET. Barbaric Crime:\\n\\n\"Acts like this one hav...  \n",
       "6316  but not a crazy long shot. So what’s happening...  \n",
       "6317  The International Swimming Federation (FINA) h...  \n",
       "6318  Join the resistance and help us fight to put A...  \n",
       "6319  Winning Iowa at all costs has also put a targe...  \n",
       "6320  Nothing will change until the collusion of the...  \n",
       "6321  Gross , U.S. Coordinator for International Com...  \n",
       "6322  \"Fabricated, mythical threats like the so-call...  \n",
       "6323  \"The speech that I gave yesterday would have b...  \n",
       "6324  They found that if all states were to legalize...  \n",
       "6325  Who cares! Questions about what her accomplish...  \n",
       "6326  The Associated Press tweeted: BREAKING: US off...  \n",
       "6327  Adam Jentleson, a spokesman for Senate Minorit...  \n",
       "6329  Ecuador’s decision to shut down his internet w...  \n",
       "6330  Clinton's campaign officials declined to comme...  \n",
       "6331  With further commentary from a handful of most...  \n",
       "6332  The Oligarchy intends to delegitimize the Trum...  \n",
       "6333  Obama is the first sitting U.S. president to v...  \n",
       "6334  They're sleeping!\" Trump said to applause. Sin...  \n",
       "\n",
       "[6295 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#正则表达式去掉一些无用的形式\n",
    "def execute(x):\n",
    "    temp=x\n",
    "    pat1 = \"[a-zA-Z]+'t\"\n",
    "    #否定词全部变为not\n",
    "    temp = re.sub(pat1, 'not', temp)\n",
    "    pat2 = \"[a-zA-Z]+’t\"\n",
    "    #否定词全部变为not\n",
    "    temp = re.sub(pat2, 'not', temp)\n",
    "    #邮箱地址\n",
    "    pat3=\"[\\w!#$%&'*+/=?^_`{|}~-]+(?:\\.[\\w!#$%&'*+/=?^_`{|}~-]+)*@(?:[\\w](?:[\\w-]*[\\w])?\\.)+[\\w](?:[\\w-]*[\\w])?\"\n",
    "    temp = re.sub(pat3, 'email', temp)\n",
    "    #url网址\n",
    "    pat4=\"[a-zA-z]+://[^\\s]*\"\n",
    "    temp = re.sub(pat4, 'url', temp)\n",
    "    #日期\n",
    "    pat5=\"([0-9]{3}[1-9]|[0-9]{2}[1-9][0-9]{1}|[0-9]{1}[1-9][0-9]{2}|[1-9][0-9]{3})-(((0[13578]|1[02])-(0[1-9]|[12][0-9]|3[01]))|((0[469]|11)-(0[1-9]|[12][0-9]|30))|(02-(0[1-9]|[1][0-9]|2[0-8])))\"\n",
    "    temp = re.sub(pat5, 'date', temp)\n",
    "    #电话号码 qq号码等 各种数字串\n",
    "    pat6=\"[0-9]+\"\n",
    "    temp = re.sub(pat6, 'number', temp)\n",
    "    return temp\n",
    "\n",
    "def text_execute(x):\n",
    "    return execute(x['text'])\n",
    "\n",
    "def title_execute(x):\n",
    "    return execute(x['title'])\n",
    "    \n",
    "\n",
    "df['text'] = df.apply(text_execute,axis=1)\n",
    "df['title'] = df.apply(title_execute,axis=1)\n",
    "\n",
    "df_fake=df[df['fake']==1]\n",
    "df_real=df[df['fake']==0]\n",
    "\n",
    "df_fake_test = df_fake.sample(frac=0.3)\n",
    "df_fake_train = pd.merge(df_fake, df_fake_test, how='left', indicator=True).query(\"_merge=='left_only'\").drop('_merge', 1)\n",
    "\n",
    "df_real_test = df_real.sample(frac=0.3)\n",
    "df_real_train = pd.merge(df_real, df_real_test, how='left', indicator=True).query(\"_merge=='left_only'\").drop('_merge', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "def clean_text(tokenized_list, sw):\n",
    "    new_list = []\n",
    "    for doc in tokenized_list:\n",
    "        new_list.append([token.lower() for token in doc if token.lower() not in sw])\n",
    "    return new_list\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "punctuation = punctuation+\"‘’“”，。、？（）！#：；《》【】~·……—\"\n",
    "mapping_table = {ord(char): u' ' for char in punctuation}\n",
    "\n",
    "#text1\n",
    "texts1_fake_train = df_fake_train.text1.values\n",
    "tokenized_fake_text1_train = [nltk.word_tokenize(line.translate(mapping_table)) for line in texts1_fake_train]\n",
    "cleaned_fake_text1_train = clean_text(tokenized_fake_text1_train, stop_words)\n",
    "\n",
    "texts1_real_train = df_real_train.text1.values\n",
    "tokenized_real_text1_train = [nltk.word_tokenize(line.translate(mapping_table)) for line in texts1_real_train]\n",
    "cleaned_real_text1_train = clean_text(tokenized_real_text1_train, stop_words)\n",
    "\n",
    "texts1_fake_test = df_fake_test.text1.values\n",
    "tokenized_fake_text1_test = [nltk.word_tokenize(line.translate(mapping_table)) for line in texts1_fake_test]\n",
    "cleaned_fake_text1_test = clean_text(tokenized_fake_text1_test, stop_words)\n",
    "\n",
    "texts1_real_test = df_real_test.text1.values\n",
    "tokenized_real_text1_test = [nltk.word_tokenize(line.translate(mapping_table)) for line in texts1_real_test]\n",
    "cleaned_real_text1_test = clean_text(tokenized_real_text1_test, stop_words)\n",
    "\n",
    "\n",
    "#text2\n",
    "texts2_fake_train = df_fake_train.text2.values\n",
    "tokenized_fake_text2_train = [nltk.word_tokenize(line.translate(mapping_table)) for line in texts2_fake_train]\n",
    "cleaned_fake_text2_train = clean_text(tokenized_fake_text2_train, stop_words)\n",
    "\n",
    "texts2_real_train = df_real_train.text2.values\n",
    "tokenized_real_text2_train = [nltk.word_tokenize(line.translate(mapping_table)) for line in texts2_real_train]\n",
    "cleaned_real_text2_train = clean_text(tokenized_real_text2_train, stop_words)\n",
    "\n",
    "texts2_fake_test = df_fake_test.text2.values\n",
    "tokenized_fake_text2_test = [nltk.word_tokenize(line.translate(mapping_table)) for line in texts2_fake_test]\n",
    "cleaned_fake_text2_test = clean_text(tokenized_fake_text2_test, stop_words)\n",
    "\n",
    "texts2_real_test = df_real_test.text2.values\n",
    "tokenized_real_text2_test = [nltk.word_tokenize(line.translate(mapping_table)) for line in texts2_real_test]\n",
    "cleaned_real_text2_test = clean_text(tokenized_real_text2_test, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#title\n",
    "title_fake_train = df_fake_train.title.values\n",
    "tokenized_fake_title_train = [nltk.word_tokenize(line.translate(mapping_table)) for line in title_fake_train]\n",
    "cleaned_fake_title_train = clean_text(tokenized_fake_title_train, stop_words)\n",
    "\n",
    "title_real_train = df_real_train.title.values\n",
    "tokenized_real_title_train = [nltk.word_tokenize(line.translate(mapping_table)) for line in title_real_train]\n",
    "cleaned_real_title_train = clean_text(tokenized_real_title_train, stop_words)\n",
    "\n",
    "title_fake_test = df_fake_test.title.values\n",
    "tokenized_fake_title_test = [nltk.word_tokenize(line.translate(mapping_table)) for line in title_fake_test]\n",
    "cleaned_fake_title_test = clean_text(tokenized_fake_title_test, stop_words)\n",
    "\n",
    "title_real_test = df_real_test.title.values\n",
    "tokenized_real_title_test = [nltk.word_tokenize(line.translate(mapping_table)) for line in title_real_test]\n",
    "cleaned_real_title_test = clean_text(tokenized_real_title_test, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgtJUi+ThSSp1/8HUviK8sSa/eIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWBC9ptQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkjr7/2i5iuHvMHoIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGJlJREFUeJzt3Xu0XnV95/H3x0S5qBAwwUkBDdgM\nyri8YKRY6wwj4gUVdAYc0GqKaKarjIrWJRdZYmfGtag6oi5HaixUdBDES4UiXjDF2ukqYLgICFhS\noRBBSVVAhRGj3/lj70Mej+ckz9k8l/PkvF9rPevs/du377Ozc77n9/vt/dupKiRJ6uIR4w5AkjS5\nTCKSpM5MIpKkzkwikqTOTCKSpM5MIpKkzkwikqTOTCKSpM5MIpKkzhaPO4CHY+nSpbVixYpxhyFJ\nE+Wqq67616paNoh9TXQSWbFiBevXrx93GJI0UZL8y6D2ZXOWJKkzk4gkqTOTiCSpM5OIJKkzk4gk\nqTOTiCSpM5OIJKkzk4gkqTOTiCSps6ElkSRnJ7k7yQ0zLHt7kkqytJ1Pkg8n2ZDkuiQHDCsuSdLg\nDHPYk08AHwE+2VuYZG/gUOD2nuKXACvbz+8BZ7Y/R2LFSV/6rbLbTn/pqA4vSRNraDWRqvom8OMZ\nFp0BvAOonrIjgE9W43JgSZLlw4pNkjQYI+0TSXI48P2q+va0RXsCd/TMb2zLJEnz2MhG8U2yM/BO\n4IUzLZ6hrGYoI8kaYA3AE57whIHFJ0mau1EOBf8kYB/g20kA9gKuTnIgTc1j75519wLunGknVbUW\nWAuwatWqGRPNIEzvJ7GPRJJ+28ias6rq+qrao6pWVNUKmsRxQFX9ALgIeF17l9ZBwL1VddeoYpMk\ndTO0mkiS84CDgaVJNgKnVdVZs6x+CXAYsAG4Hzh2WHENknd1SVrohpZEquqYbSxf0TNdwPHDikWS\nNBw+sS5J6swkIknqzCQiSerMJCJJ6swkIknqbJQPG84bM92aK0maO2sikqTOTCKSpM5MIpKkzkwi\nkqTOTCKSpM5MIpKkzkwikqTOTCKSpM5MIpKkzkwikqTOTCKSpM5MIpKkzrb7ARgdbFGShme7SyIm\nDUkanaE1ZyU5O8ndSW7oKXtfkpuTXJfkr5Ms6Vl2cpINSb6b5EXDikuSNDjD7BP5BPDiaWWXAk+t\nqqcB/wScDJBkf+Bo4N+123w0yaIhxiZJGoChJZGq+ibw42llX6uqze3s5cBe7fQRwPlV9YuquhXY\nABw4rNgkSYMxzruzXg98uZ3eE7ijZ9nGtkySNI+NJYkkeSewGTh3qmiG1WqWbdckWZ9k/aZNm4YV\noiSpDyNPIklWAy8DXlNVU4liI7B3z2p7AXfOtH1Vra2qVVW1atmyZcMNVpK0VSNNIkleDJwIHF5V\n9/csugg4OskOSfYBVgJXjjI2SdLcDe05kSTnAQcDS5NsBE6juRtrB+DSJACXV9UfV9V3klwA3EjT\nzHV8Vf1qWLFJkgZjaEmkqo6Zofisraz/HuA9w4pHkjR4jp0lSepsuxv2ZFgcTkWSfps1EUlSZyYR\nSVJnJhFJUmcmEUlSZ3asj8H0TvrbTn/pmCKRpIfHmogkqTOTiCSpM5OIJKkzk4gkqTOTiCSpM5OI\nJKkzk4gkqTOTiCSpM5OIJKkzk4gkqTOTiCSpM5OIJKkzk4gkqbOhJZEkZye5O8kNPWW7J7k0yS3t\nz93a8iT5cJINSa5LcsCw4pIkDc4wayKfAF48rewkYF1VrQTWtfMALwFWtp81wJlDjEuSNCBDSyJV\n9U3gx9OKjwDOaafPAV7RU/7JalwOLEmyfFixSZIGY9R9Io+vqrsA2p97tOV7Anf0rLexLZMkzWPz\npWM9M5TVjCsma5KsT7J+06ZNQw5LkrQ1o04iP5xqpmp/3t2WbwT27llvL+DOmXZQVWuralVVrVq2\nbNlQg5Ukbd2ok8hFwOp2ejVwYU/569q7tA4C7p1q9pIkzV+Lh7XjJOcBBwNLk2wETgNOBy5Ichxw\nO3BUu/olwGHABuB+4NhhxSVJGpyhJZGqOmaWRYfMsG4Bx8/1GNd//15WnPSluW4mSRqQ+dKxLkma\nQCYRSVJnJhFJUmcmEUlSZyYRSVJnJhFJUmdDu8V3oZp+y/Ftp790TJFI0vD1VRNJ8tRhByJJmjz9\nNmf9RZIrk/xJkiVDjUiSNDH6SiJV9QfAa2gGSVyf5NNJDh1qZJKkea/vjvWqugU4FTgR+A/Ah5Pc\nnOQ/DSs4SdL81m+fyNOSnAHcBDwfeHlVPaWdPmOI8UmS5rF+7876CPBx4JSqemCqsKruTHLqUCKT\nJM17/SaRw4AHqupXAEkeAexYVfdX1aeGFp0kaV7rt0/k68BOPfM7t2WSpAWs3ySyY1X9bGqmnd55\nOCFJkiZFv0nk50kOmJpJ8izgga2sL0laAPrtEzkB+GySO9v55cB/GU5IkqRJ0VcSqapvJXkysB8Q\n4Oaq+uVQI5MkzXtzGYDx2cCKdptnJqGqPjmUqCRJE6GvJJLkU8CTgGuBX7XFBXRKIkneCryh3cf1\nwLE0TWTnA7sDVwOvraoHu+xfkjQa/dZEVgH7V1U93AMm2RN4c7u/B5JcABxN8yzKGVV1fpK/AI4D\nzny4x5MkDU+/d2fdAPybAR53MbBTksU0twrfRTOEyufa5ecArxjg8SRJQ9BvTWQpcGOSK4FfTBVW\n1eFzPWBVfT/J+4HbaW4T/hpwFXBPVW1uV9sI7DnXfUuSRqvfJPLuQR0wyW7AEcA+wD3AZ4GXzLDq\njE1nSdYAawAW7bJsUGENzfQ3HUrS9qTfW3z/LskTgZVV9fUkOwOLOh7zBcCtVbUJIMkXgN8HliRZ\n3NZG9gLunGnjqloLrAXYYfnKh91HI0nqrt+h4N9I01/xsbZoT+CLHY95O3BQkp2TBDgEuBG4DDiy\nXWc1cGHH/UuSRqTfjvXjgecC98FDL6jao8sBq+oKmoR0Nc3tvY+gqVmcCLwtyQbgccBZXfYvSRqd\nfvtEflFVDzYVB2jvqurclFRVpwGnTSv+HnBg131Kkkav35rI3yU5hea23ENpOsP/ZnhhSZImQb9J\n5CRgE03z038FLqF537okaQHr9+6sX9O8Hvfjww1HkjRJ+h0761Zm6AOpqn0HHpEkaWLMZeysKTsC\nR9EMlChJWsD66hOpqh/1fL5fVR+kGetKkrSA9ducdUDP7CNoaiaPHUpEkqSJ0W9z1v/qmd4M3Aa8\nauDRSJImSr93Z/3HYQciSZo8/TZnvW1ry6vqA4MJR5I0SeZyd9azgYva+ZcD3wTuGEZQkqTJMJeX\nUh1QVT8FSPJu4LNV9YZhBSZJmv/6HfbkCcCDPfMPAisGHo0kaaL0WxP5FHBlkr+meXL9lcAnhxaV\nJGki9Ht31nuSfBl4Xlt0bFVdM7yw1I/pr9697fSXjikSSQtVv81ZADsD91XVh4CNSfYZUkySpAnR\n7+txT6N58+DJbdEjgf8zrKAkSZOh35rIK4HDgZ8DVNWdOOyJJC14/SaRB6uqaIeDT/Lo4YUkSZoU\n/SaRC5J8DFiS5I3A1/EFVZK04PV7d9b723er3wfsB7yrqi7tetAkS4C/BJ5KU7t5PfBd4DM0z5/c\nBryqqn7S9RiSpOHbZhJJsgj4alW9AOicOKb5EPCVqjoyyaNo7vw6BVhXVacnOYnmve4nDuh4kqQh\n2GZzVlX9Crg/ya6DOGCSXYB/D5zV7v/BqroHOAI4p13tHOAVgzieJGl4+n1i/f8B1ye5lPYOLYCq\nenOHY+4LbAL+KsnTgauAtwCPr6q72v3elWSPDvuWJI1Qv0nkS+1nUMc8AHhTVV2R5EM0TVd9SbIG\nWAOwaJdlAwppvKY/eQ4+fS5pMmw1iSR5QlXdXlXnbG29OdoIbKyqK9r5z9EkkR8mWd7WQpYDd8+0\ncVWtBdYC7LB8ZQ0wLknSHG2rT+SLUxNJPj+IA1bVD4A7kuzXFh0C3EjzrpLVbdlq4MJBHE+SNDzb\nas5Kz/S+Azzum4Bz2zuzvgccS5PQLkhyHHA7cNQAjydJGoJtJZGaZfphqaprad6WON0hgzrGpHOE\nXkmTYFtJ5OlJ7qOpkezUTtPOV1XtMtToJEnz2laTSFUtGlUgkqTJM5f3iUiS9BtMIpKkzkwikqTO\nTCKSpM5MIpKkzkwikqTOTCKSpM5MIpKkzkwikqTOTCKSpM5MIpKkzkwikqTOTCKSpM5MIpKkzkwi\nkqTOtvVSKs0T0990OOrj+WZFSTOxJiJJ6swkIknqbGxJJMmiJNckubid3yfJFUluSfKZJI8aV2yS\npP6MsybyFuCmnvk/B86oqpXAT4DjxhKVJKlvY+lYT7IX8FLgPcDbkgR4PvDqdpVzgHcDZ44jvu3Z\nTB30dppL6mpcNZEPAu8Aft3OPw64p6o2t/MbgT3HEZgkqX8jr4kkeRlwd1VdleTgqeIZVq1Ztl8D\nrAFYtMuyocS4PRn1rcGSFpZxNGc9Fzg8yWHAjsAuNDWTJUkWt7WRvYA7Z9q4qtYCawF2WL5yxkQj\nSRqNkTdnVdXJVbVXVa0Ajgb+tqpeA1wGHNmuthq4cNSxSZLmZj49sX4icH6S/wlcA5w15ngmjk1X\nkkZtrEmkqr4BfKOd/h5w4DjjkSTNjU+sS5I6m0/NWRoTm8EkdWVNRJLUmUlEktSZzVnqi8OlSJqJ\nNRFJUmcmEUlSZyYRSVJnJhFJUmcmEUlSZyYRSVJn3uKrgfE2YGnhMYlopEw00vbF5ixJUmfWRDTv\nWFuRJodJRJ05+q8km7MkSZ2ZRCRJnZlEJEmd2SeiobLfRNq+jbwmkmTvJJcluSnJd5K8pS3fPcml\nSW5pf+426tgkSXMzjuaszcCfVtVTgIOA45PsD5wErKuqlcC6dl6SNI+NPIlU1V1VdXU7/VPgJmBP\n4AjgnHa1c4BXjDo2SdLcjLVjPckK4JnAFcDjq+ouaBINsMf4IpMk9WNsHetJHgN8Hjihqu5L0u92\na4A1AIt2WTa8ADVxpnfi+5S7NHxjqYkkeSRNAjm3qr7QFv8wyfJ2+XLg7pm2raq1VbWqqlYt2nnX\n0QQsSZrROO7OCnAWcFNVfaBn0UXA6nZ6NXDhqGOTJM3NOJqzngu8Frg+ybVt2SnA6cAFSY4DbgeO\nGkNskqQ5GHkSqar/C8zWAXLIKGORJD08DnsiSerMYU80dl2GRnE4FWl+MIlI0/hSLKl/NmdJkjqz\nJqLtVr81CpvGpO6siUiSOrMmogVlULUO+02khjURSVJn1kSkecaBJDVJTCJSH/ppBvOXvxYim7Mk\nSZ1ZE5H0G6xRaS5MIpoIPsshzU82Z0mSOjOJSJI6szlLGqFx9zeM+/gajVE+DGtNRJLUmTURaUi6\nPFvycPbd5S/NrjFag/lNC7mGZxKRNBQL+RfrQmISkea5fmsr47wNej7egt1PTCa2h2/e9YkkeXGS\n7ybZkOSkcccjSZrdvKqJJFkE/G/gUGAj8K0kF1XVjeONTNJCMAk1qvlWe5pXSQQ4ENhQVd8DSHI+\ncARgEpEm3CT8gp4E8+1Gh/nWnLUncEfP/Ma2TJI0D6Wqxh3DQ5IcBbyoqt7Qzr8WOLCq3tSzzhpg\nTTv7VOCGkQc6Py0F/nXcQcwTnostPBdbeC622K+qHjuIHc235qyNwN4983sBd/auUFVrgbUASdZX\n1arRhTd/eS628Fxs4bnYwnOxRZL1g9rXfGvO+hawMsk+SR4FHA1cNOaYJEmzmFc1karanOS/AV8F\nFgFnV9V3xhyWJGkW8yqJAFTVJcAlfa6+dpixTBjPxRaeiy08F1t4LrYY2LmYVx3rkqTJMt/6RCRJ\nE2Rik8hCGh4lyd5JLktyU5LvJHlLW757kkuT3NL+3K0tT5IPt+fmuiQHjPcbDF6SRUmuSXJxO79P\nkivac/GZ9sYMkuzQzm9ol68YZ9yDlmRJks8lubm9Pp6zUK+LJG9t/3/ckOS8JDsupOsiydlJ7k5y\nQ0/ZnK+FJKvb9W9Jsnpbx53IJNIzPMpLgP2BY5LsP96ohmoz8KdV9RTgIOD49vueBKyrqpXAunYe\nmvOysv2sAc4cfchD9xbgpp75PwfOaM/FT4Dj2vLjgJ9U1e8CZ7TrbU8+BHylqp4MPJ3mnCy46yLJ\nnsCbgVVV9VSaG3OOZmFdF58AXjytbE7XQpLdgdOA36MZQeS0qcQzq6qauA/wHOCrPfMnAyePO64R\nfv8LacYX+y6wvC1bDny3nf4YcEzP+g+ttz18aJ4fWgc8H7gYCM1DZIunXx80d/o9p51e3K6XcX+H\nAZ2HXYBbp3+fhXhdsGW0i93bf+eLgRcttOsCWAHc0PVaAI4BPtZT/hvrzfSZyJoIC3h4lLba/Uzg\nCuDxVXUXQPtzj3a17f38fBB4B/Drdv5xwD1Vtbmd7/2+D52Ldvm97frbg32BTcBftU17f5nk0SzA\n66Kqvg+8H7gduIvm3/kqFuZ10Wuu18Kcr5FJTSKZoWy7v80syWOAzwMnVNV9W1t1hrLt4vwkeRlw\nd1Vd1Vs8w6rVx7JJtxg4ADizqp4J/JwtzRUz2W7PRdvkcgSwD/A7wKNpmmymWwjXRT9m+/5zPi+T\nmkS2OTzK9ibJI2kSyLlV9YW2+IdJlrfLlwN3t+Xb8/l5LnB4ktuA82matD4ILEky9dxT7/d96Fy0\ny3cFfjzKgIdoI7Cxqq5o5z9Hk1QW4nXxAuDWqtpUVb8EvgD8Pgvzuug112thztfIpCaRBTU8SpIA\nZwE3VdUHehZdBEzdPbGapq9kqvx17R0YBwH3TlVpJ11VnVxVe1XVCpp/97+tqtcAlwFHtqtNPxdT\n5+jIdv3t4i/OqvoBcEeS/dqiQ2hem7DgrguaZqyDkuzc/n+ZOhcL7rqYZq7XwleBFybZra3dvbAt\nm924O4IeRgfSYcA/Af8MvHPc8Qz5u/4BTZXyOuDa9nMYTRvuOuCW9ufu7fqhuXvtn4Hrae5YGfv3\nGMJ5ORi4uJ3eF7gS2AB8FtihLd+xnd/QLt933HEP+Bw8A1jfXhtfBHZbqNcF8GfAzTQje38K2GEh\nXRfAeTT9Qb+kqVEc1+VaAF7fnpcNwLHbOq5PrEuSOpvU5ixJ0jxgEpEkdWYSkSR1ZhKRJHVmEpEk\ndWYS0ci1I8/+ScdtL0myZA7rL2tHab0myfO2st5tSZZ2jOmEJDt32bbd/pSe6RlHbJ5hm3cneXvX\nY/YR04okr+6Z/6MkHxnW8TS5TCIahyXAjEmkHaF5VlV1WFXdM4djHQLcXFXPrKq/n8N2c3EC0DmJ\nAKf0TM82YvOorQBeva2VJJOIxuF04ElJrk3yviQHt399f5rmwSeSfDHJVe1f42umNpyqMbR/Kd+U\n5OPtOl9LslPvQZI8A3gvcFh7rJ2SnJlkfbvNn00PrF3nK0ne2M7/YZIr2+0/Nj3JJXkzzVhNlyW5\nrC17YZJ/THJ1ks8meUySXdO8/2a/dp3zkrwxyenATu3+z62qu6rqaoCq+inN0O59D5I4W7xJfpbk\nPUm+neTyJI9vy5/Uzn8ryX9P8rOef6Pntft5a1v2O+25uSXJe/uNSdu5cT9l6Wfhffjt4aoPphk8\ncJ+esqkna3eieQL5ce38bcDSdh+bgWe05RcAfzjDsf4I+MgM+10EfAN4Ws9+VwBfB17Xlj0F+Bvg\nke38R6eWTTvGbcDSdnop8E3g0e38icC72ulDgX+kGa7lKz3b/2wr5+l2YJcZlr0bePu0slnjpRnx\n4OXt9HuBU9vpi2mH+gb+eCoWekYD6DmP36MZY2pH4F+Avcd9LfkZ/2dqYDJp3K6sqlt75t+c5JXt\n9N40L8/50bRtbq2qa9vpq2h+6W7Lq9qazWKa9yfsTzNkCDTjCr23qs5t5w8BngV8qxmOiZ3YMoDd\nbA5q9/kP7TaPokkcVNWlSY6iGW7i6VvbSfofsbnX1uJ9kCZhQHOuDm2nnwO8op3+NM1w6rNZV1X3\ntvHdCDyR3xw2XAuQSUTzxc+nJpIcTDMq63Oq6v4k36D563e6X/RM/4rml+askuwDvB14dlX9JMkn\npu33H4CXJPl0VU0Ni31OVZ08h+8R4NKqOmaG4z+CprbwAM3LkzbOEudMIzb3e+zZ4v1l+52gOVdd\n/u9PP9/+/pB9IhqLnwKP3cryXWleXXp/kifT/HU/CLvQJKt72z6B6e+beBdNbeej7fw64Mgke8BD\n76t+4gz77f0+lwPPTfK77TY7J/m37bK30vRxHAOc3SYLgF9OTbcj0M40YnM/+o231+XAf26nj57l\nO0mzMolo5KrqRzTNPTcked8Mq3wFWJzkOuB/0PyiG8Rxvw1cA3wHOJum5jHdCcCOSd5bVTcCpwJf\na2O5lKYJbLq1wJeTXFZVm2j6D85rt7kceHKbSN5Ac+fV39P0m5zas/11Sc6leV/Ka4Hnt53a1yY5\nbJavdGqSjVOfOcQ7/fu+LcmV7br3tuXXAZvbjvi3zrq1FjxH8ZUWsDTPtzxQVZXkaJpO9iPGHZcm\nh22a0sL2LOAjbTPaPTTvkpD6Zk1EktSZfSKSpM5MIpKkzkwikqTOTCKSpM5MIpKkzkwikqTO/j81\nUH3D8YyRPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnRkikqTODBFJUmeGiCSpM0NEktTZ/wcgXgdOT22Z2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGI5JREFUeJzt3XuUZWV55/HvT1AQURukIZ1umAbD\nEA3jBVsHNRoURSQKZoKKYbRH0U6i4zWJgpdgsmYmuDSirjjG9hLQEBTxAuIFkUA0iYLdgHI1tMBA\nC0obFRSIXHzmj72LPhZV1ad2n1PnnK7vZ62zau93356ze3c99b577/dNVSFJUhf3G3UAkqTJZRKR\nJHVmEpEkdWYSkSR1ZhKRJHVmEpEkdWYSkSR1ZhKRJHVmEpEkdbb9qAPYGrvttlutXLly1GFI0kRZ\nv379j6pq6SD2NdFJZOXKlaxbt27UYUjSREny/wa1L5uzJEmdmUQkSZ2ZRCRJnZlEJEmdmUQkSZ2Z\nRCRJnZlEJEmdmUQkSZ2ZRCRJnQ0tiST5aJKbk1w2w7I/TVJJdmvnk+R9STYk+U6SA4YVlyRpcIZZ\nEzkJOHR6YZI9gWcC1/cUPxvYt/2sAT4wxLgkSQMytCRSVV8DfjzDohOBNwLVU3YE8LFqfBNYkmTZ\nsGKTJA3Ggt4TSXI48P2q+va0RcuBG3rmN7ZlkqQxtmC9+CbZCXgLcMhMi2coqxnKSLKGpsmLvfba\na2DxSZLmbyFrIg8H9ga+neQ6YAVwUZJfo6l57Nmz7grgxpl2UlVrq2pVVa1aunQg3eFLkjpasCRS\nVZdW1e5VtbKqVtIkjgOq6gfAmcBL2qe0DgRuqaqbFio2SVI3w3zE91TgG8B+STYmOWaO1b8IXANs\nAD4EvHJYcUmSBmdo90Sq6kVbWL6yZ7qAVw0rFknScPjGuiSpM5OIJKkzk4gkqTOTiCSpM5OIJKkz\nk4gkqTOTiCSpM5OIJKkzk4gkqTOTiCSpM5OIJKkzk4gkqTOTiCSpM5OIJKkzk4gkqTOTiCSpM5OI\nJKkzk4gkqTOTiCSpM5OIJKmzoSWRJB9NcnOSy3rK3pnkqiTfSfLZJEt6lh2XZEOS7yZ51rDikiQN\nzjBrIicBh04rOwfYv6oeBfwbcBxAkkcCRwG/1W7zf5NsN8TYJEkDMLQkUlVfA348rewrVXV3O/tN\nYEU7fQTwiar6RVVdC2wAnjCs2CRJgzHKeyIvA77UTi8HbuhZtrEtkySNsZEkkSRvAe4GTpkqmmG1\nmmXbNUnWJVm3adOmYYUoSerDgieRJKuB5wBHV9VUotgI7Nmz2grgxpm2r6q1VbWqqlYtXbp0uMFK\nkua0oEkkyaHAm4DDq+r2nkVnAkcl2SHJ3sC+wIULGZskaf62H9aOk5wKHATslmQjcDzN01g7AOck\nAfhmVf1RVV2e5DTgCppmrldV1T3Dik2SNBjZ3KI0eVatWlXr1q0bdRiSNFGSrK+qVYPYl2+sS5I6\nM4lIkjoziUiSOjOJSJI6M4lIkjoziUiSOjOJSJI6M4lIkjoziUiSOjOJSJI6M4lIkjoziUiSOjOJ\nSJI6M4lIkjoziUiSOjOJSJI6M4lIkjoziUiSOjOJSJI6M4lIkjobWhJJ8tEkNye5rKds1yTnJLm6\n/blLW54k70uyIcl3khwwrLgkSYMzzJrIScCh08qOBc6tqn2Bc9t5gGcD+7afNcAHhhiXJGlAhpZE\nquprwI+nFR8BnNxOnww8r6f8Y9X4JrAkybJhxSZJGoyFvieyR1XdBND+3L0tXw7c0LPexrZMkjTG\nxuXGemYoqxlXTNYkWZdk3aZNm4YcliRpLgudRH441UzV/ry5Ld8I7Nmz3grgxpl2UFVrq2pVVa1a\nunTpUIOVJM1toZPImcDqdno1cEZP+Uvap7QOBG6ZavaSJI2v7Ye14ySnAgcBuyXZCBwPnACcluQY\n4Hrg+e3qXwQOAzYAtwMvHVZckqTBGVoSqaoXzbLo4BnWLeBVw4pFkjQc43JjXZI0gUwikqTOTCKS\npM5MIpKkzkwikqTOTCKSpM5MIpKkzvpKIkn2H3YgkqTJ029N5G+TXJjklUmWDDUiSdLE6CuJVNVv\nA0fTdJK4Lsk/JHnmUCOTJI29vu+JVNXVwFuBNwG/A7wvyVVJ/tuwgpMkjbd+74k8KsmJwJXA04Hn\nVtUj2ukThxifJGmM9dsB498AHwLeXFV3TBVW1Y1J3jqUyCRJY6/fJHIYcEdV3QOQ5H7AjlV1e1V9\nfGjRSZLGWr/3RL4KPLBnfqe2TJK0iPWbRHasqp9PzbTTOw0nJEnSpOg3idyW5ICpmSSPA+6YY31J\n0iLQ7z2R1wGfSnJjO78MeOFwQpIkTYq+kkhVfSvJbwL7AQGuqqq7hhqZJGnszWeM9ccDK9ttHpuE\nqvrYUKKSJE2EvpJIko8DDwcuAe5piwvolESSvB54ebuPS4GX0jSRfQLYFbgIeHFV3dll/5KkhdFv\nTWQV8Miqqq09YJLlwGva/d2R5DTgKJp3UU6sqk8k+VvgGOADW3s8SdLw9Pt01mXArw3wuNsDD0yy\nPc2jwjfRdKFyerv8ZOB5AzyeJGkI+q2J7AZckeRC4BdThVV1+HwPWFXfT/Iu4Hqax4S/AqwHflpV\nd7erbQSWz3ffkqSF1W8SefugDphkF+AIYG/gp8CngGfPsOqMTWdJ1gBrAPbaa69BhSVJ6qDf8UT+\nCbgOuH87/S2am99dPAO4tqo2tY8JfwZ4ErCkbd4CWAHcONPGVbW2qlZV1aqlS5d2DEGSNAj9dgX/\nCpr7FR9si5YDn+t4zOuBA5PslCTAwcAVwHnAke06q4EzOu5fkrRA+r2x/irgycCtcO8AVbt3OWBV\nXUCTkC6iebz3fsBamsGu3pBkA/Aw4CNd9i9JWjj93hP5RVXd2VQcoG126vy4b1UdDxw/rfga4Ald\n9ylJWnj91kT+KcmbaR7LfSbNzfDPDy8sSdIk6DeJHAtsoml++kPgizTjrUuSFrF+O2D8Jc3wuB8a\nbjiSpEnSb99Z1zLDPZCq2mfgEUmSJsZ8+s6asiPwfJqOEiVJi1i/Lxv+e8/n+1X1Hpq+riRJi1i/\nzVkH9Mzej6Zm8uChRCRJmhj9Nmf9dc/03TRdoLxg4NFIkiZKv09nPW3YgUiSJk+/zVlvmGt5Vb17\nMOFIkibJfJ7OejxwZjv/XOBrwA3DCEqSNBnmMyjVAVX1M4Akbwc+VVUvH1ZgkqTx12+3J3sBd/bM\n3wmsHHg0kqSJ0m9N5OPAhUk+S/Pm+u8BHxtaVJKkidDv01n/O8mXgKe0RS+tqouHF5YkaRL025wF\nsBNwa1W9F9iYZO8hxSRJmhD9Do97PM3Ig8e1RfcH/n5YQUmSJkO/NZHfAw4HbgOoqhux2xNJWvT6\nTSJ3VlXRdgef5EHDC0mSNCn6TSKnJfkgsCTJK4Cv4gBVkrTo9ft01rvasdVvBfYD/ryqzul60CRL\ngA8D+9PUbl4GfBf4JM37J9cBL6iqn3Q9hiRp+LaYRJJsB5xdVc8AOieOad4LfLmqjkzyAJonv94M\nnFtVJyQ5lmZc9zcN6Hj3WnnsF35l/roTfnfQh5CkRWOLzVlVdQ9we5KHDuKASR4CPBX4SLv/O6vq\np8ARwMntaicDzxvE8SRJw9PvG+v/AVya5BzaJ7QAquo1HY65D7AJ+LskjwbWA68F9qiqm9r93pRk\n9w77liQtoH6TyBfaz6COeQDw6qq6IMl7aZqu+pJkDbAGYK+99hpQSJKkLuZMIkn2qqrrq+rkudab\np43Axqq6oJ0/nSaJ/DDJsrYWsgy4eaaNq2otsBZg1apVNcC4JEnztKV7Ip+bmkjy6UEcsKp+ANyQ\nZL+26GDgCpqxSla3ZauBMwZxPEnS8GypOSs90/sM8LivBk5pn8y6BngpTUI7LckxwPXA8wd4PEnS\nEGwpidQs01ulqi6hGS1xuoMHdQxJ0vBtKYk8OsmtNDWSB7bTtPNVVQ8ZanSSpLE2ZxKpqu0WKhBJ\n0uSZz3gikiT9CpOIJKkzk4gkqTOTiCSpM5OIJKkzk4gkqTOTiCSpM5OIJKkzk4gkqbN+xxNZFHqH\nznXYXEnaMmsikqTOTCKSpM622eas3qYpSdJwWBORJHVmEpEkdWYSkSR1ts3eE+nXQt07mX4cHyGW\ntC2wJiJJ6mxkSSTJdkkuTnJWO793kguSXJ3kk0keMKrYJEn9GWVN5LXAlT3z7wBOrKp9gZ8Ax4wk\nKklS30aSRJKsAH4X+HA7H+DpwOntKicDzxtFbJKk/o2qJvIe4I3AL9v5hwE/raq72/mNwPJRBCZJ\n6t+CJ5EkzwFurqr1vcUzrFqzbL8mybok6zZt2jSUGCVJ/RnFI75PBg5PchiwI/AQmprJkiTbt7WR\nFcCNM21cVWuBtQCrVq2aMdEMgz38StJ9LXhNpKqOq6oVVbUSOAr4x6o6GjgPOLJdbTVwxkLHJkma\nn3F6T+RNwBuSbKC5R/KREccjSdqCkb6xXlXnA+e309cATxhlPJKk+RmnmogkacKYRCRJnS36DhgH\nzae4JC0m1kQkSZ1ZE5mFw+tK0paZRDqwyUqSGttUEhlF7cEai6TFzHsikqTOJromcun3b7EmIEkj\nZE1EktSZSUSS1JlJRJLUmUlEktSZSUSS1JlJRJLUmUlEktSZSUSS1JlJRJLUmUlEktTZRHd7si2a\n3o2LvQRLGmcLXhNJsmeS85JcmeTyJK9ty3dNck6Sq9ufuyx0bJKk+RlFTeRu4E+q6qIkDwbWJzkH\n+B/AuVV1QpJjgWOBN40gvoGxc0hJ27oFTyJVdRNwUzv9syRXAsuBI4CD2tVOBs5nwpPIXBzYStK2\nYKQ31pOsBB4LXADs0SaYqUSz++gikyT1Y2RJJMnOwKeB11XVrfPYbk2SdUnW3XP7LcMLUJK0RSN5\nOivJ/WkSyClV9Zm2+IdJllXVTUmWATfPtG1VrQXWAuywbN9akIDHhE1gksbNKJ7OCvAR4MqqenfP\nojOB1e30auCMhY5NkjQ/o6iJPBl4MXBpkkvasjcDJwCnJTkGuB54/ghikyTNwyiezvpnILMsPngh\nY5kE/T4mPFtTly8vShomuz2RJHVmtyeLmDfqJW0tk8g2aK4mMN+ilzRINmdJkjoziUiSOrM5awx0\naWKyWUrSODCJaKS8uS9NNpuzJEmdWRPRVrEmIS1uJhEtCJONtG2yOUuS1Jk1Ec1o3GoO4xaPpIZJ\nRED/b7mPwy9wO5WUxofNWZKkzqyJaGz5QqU0/kwimpdB/GKf1ORgM5p0XzZnSZI6syaigZnUGsag\nWWPRYmIS0aLR71NmC/U0mslG2wKTiBalLmPXj4rJRuNs7O6JJDk0yXeTbEhy7KjjkSTNLlU16hju\nlWQ74N+AZwIbgW8BL6qqK2Zaf4dl+9ay1e9ZwAg17nr/Sl/IWkS/xx1EfLPVRPqtsfQbXxdda02z\nNSGOYy1smM2dC9WUmmR9Va0axL7GrTnrCcCGqroGIMkngCOAGZOINN2omp8W8rhdmuIGnRyGuY8u\nvSfMlWy6JM2uCXlrk+Zc++73OAvdw8S4NWctB27omd/YlkmSxtC4NWc9H3hWVb28nX8x8ISqenXP\nOmuANe3s/sBlCx7oeNoN+NGogxgTnovNPBebeS4226+qHjyIHY1bc9ZGYM+e+RXAjb0rVNVaYC1A\nknWDatebdJ6LzTwXm3kuNvNcbJZk3aD2NW7NWd8C9k2yd5IHAEcBZ444JknSLMaqJlJVdyf5n8DZ\nwHbAR6vq8hGHJUmaxVglEYCq+iLwxT5XXzvMWCaM52Izz8VmnovNPBebDexcjNWNdUnSZBm3eyKS\npAkysUlkMXWPkmTPJOcluTLJ5Ule25bvmuScJFe3P3dpy5Pkfe25+U6SA0b7DQYvyXZJLk5yVju/\nd5IL2nPxyfbBDJLs0M5vaJevHGXcg5ZkSZLTk1zVXh9PXKzXRZLXt/8/LktyapIdF9N1keSjSW5O\ncllP2byvhSSr2/WvTrJ6S8edyCTSdo/yfuDZwCOBFyV55GijGqq7gT+pqkcABwKvar/vscC5VbUv\ncG47D8152bf9rAE+sPAhD91rgSt75t8BnNiei58Ax7TlxwA/qarfAE5s19uWvBf4clX9JvBomnOy\n6K6LJMuB1wCrqmp/mgdzjmJxXRcnAYdOK5vXtZBkV+B44L/S9CBy/FTimVVVTdwHeCJwds/8ccBx\no45rAb//GTT9i30XWNaWLQO+205/kKbPsan1711vW/jQvD90LvB04CwgNC+RbT/9+qB50u+J7fT2\n7XoZ9XcY0Hl4CHDt9O+zGK8LNvd2sWv773wW8KzFdl0AK4HLul4LwIuAD/aU/8p6M30msibCIu4e\npa12Pxa4ANijqm4CaH/u3q62rZ+f9wBvBH7Zzj8M+GlV3d3O937fe89Fu/yWdv1twT7AJuDv2qa9\nDyd5EIvwuqiq7wPvAq4HbqL5d17P4rwues33Wpj3NTKpSSQzlG3zj5kl2Rn4NPC6qrp1rlVnKNsm\nzk+S5wA3V9X63uIZVq0+lk267YEDgA9U1WOB29jcXDGTbfZctE0uRwB7A78OPIimyWa6xXBd9GO2\n7z/v8zKpSWSL3aNsa5LcnyaBnFJVn2mLf5hkWbt8GXBzW74tn58nA4cnuQ74BE2T1nuAJUmm3nvq\n/b73not2+UOBHy9kwEO0EdhYVRe086fTJJXFeF08A7i2qjZV1V3AZ4AnsTivi17zvRbmfY1MahJZ\nVN2jJAnwEeDKqnp3z6IzgamnJ1bT3CuZKn9J+wTGgcAtU1XaSVdVx1XViqpaSfPv/o9VdTRwHnBk\nu9r0czF1jo5s198m/uKsqh8ANyTZry06mGbYhEV3XdA0Yx2YZKf2/8vUuVh018U0870WzgYOSbJL\nW7s7pC2b3ahvBG3FDaTDaAaw+h7wllHHM+Tv+ts0VcrvAJe0n8No2nDPBa5uf+7arh+ap9e+B1xK\n88TKyL/HEM7LQcBZ7fQ+wIXABuBTwA5t+Y7t/IZ2+T6jjnvA5+AxwLr22vgcsMtivS6AvwCuounZ\n++PADovpugBOpbkfdBdNjeKYLtcC8LL2vGwAXrql4/rGuiSps0ltzpIkjQGTiCSpM5OIJKkzk4gk\nqTOTiCSpM5OIRqbtgfaVW7H965LsNMuyp7Q9ul6S5IGzrLOyt8fTeR57a2NfmeQPeuafmWR9kkvb\nn0+fZbvzkwxtnPAkByV5Us/8SUmOnGsbLW4mEY3SEqDzL2LgdcCMSQQ4GnhXVT2mqu7YimPMZmtj\nXwn8Qc/8j4DnVtV/oXkp7ONbse+tcRDNm95SX0wiGqUTgIe3tYV3AiT5syTfasc4+Iu27EFJvpDk\n2+1YES9M8hqaPpLOS3Je706TvBx4AfDnSU5JsnOSc5Nc1P6lf8T0QJLs03Zi+Pg0Y5W8syeOP9yK\n2B/fzu/Yfo/Lk+zfbv+UdvvXV9XFVTXVvcTlwI5JdujnJM4Wb1urOD+bxxs5pX2bmySHtWX/nGZc\nibPSdO75R8Dr27ie0h7iqUn+Nck11kp0H6N+y9LP4v1w326rD6EZ+zk0f+CcBTwV+H3gQz3rPbT9\neR2w2yz7Pgk4sp3eHnhIO70bzZu4mTo+sB9wMfCYdp01wFvb6R1o3gjfu0vs7bL/RdPD7Ptphyyg\n5237GWI/EvjqLMvOZ9qb5rPF2x7jFpr+j+4HfIOm94MdaXpq3bvd5lQ2v/n/duBPp53HT7XbPxLY\nMOrrxs94faY6JpPGwSHt5+J2fmeaQXO+DrwryTtoftl9fZ77DfB/kjyVpvv45cAe7bKlNP0J/X5V\nXd4Tx6N6/up+aBvHtR1i/xrwlzT9vf0HzcBJswea/BbNAEmH9Pvl5oj3TuDCqtrY7vsSmuT3c+Ca\nqpr6PqfSJKLZfK6qfglckWSPOdbTImQS0TgJ8FdV9cH7LEgeR9Nf2F8l+UpV/eU89ns0TbJ4XFXd\nlaYH4B3bZbfQ/FX+ZJpmpKk4Xl1Vc3c812fsNAMl7Qzcvz3ubTPuIFkBfBZ4SVV9b57Hvk+8SQ4C\nftFTdA/N//mZuvueS+8+5ruttnHeE9Eo/Qx4cM/82cDL0oybQpLlSXZP8uvA7VX19zTNQgfMsv1s\nHkozBsldSZ4G/KeeZXcCz6Pp0XTqRvfZwB+n6X6fJP85zWBP8469XbYWeBtwCpuHYf2V7ZMsAb5A\n09z1L318p179xNvrKmCfbB5X/IVzfC9pTtZENDJV9e9J/qV9zPZLVfVnSR4BfKO9//tz4L8DvwG8\nM8kvaXoo/eN2F2uBLyW5qaqeNsehTgE+n2QdTQ/IV02L47Y0g12dk+Q24MM0zT4XtTeiN9EkmnnH\nnuRQ4O6q+ock2wH/2j6++3Xg7iTfprnv8KD2e74tydvawxxSVTdzX19Iclc7/Q2aJDBnvNNivyPN\n48lfTvIjml5sp3weOL19+ODVs+1DmmIvvtIilGTnqvp5m3TeD1xdVSeOOi5NHpuzpMXpFe2N9stp\nmvtmupcjbZE1EUlSZ9ZEJEmdmUQkSZ2ZRCRJnZlEJEmdmUQkSZ2ZRCRJnf1/hKizM4WTkg4AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "numWords=[]\n",
    "for item in cleaned_real_text1_train:\n",
    "    numWords.append(len(item))\n",
    "\n",
    "plt.hist(numWords, bins=400)\n",
    "plt.xlabel('train real text1 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 75])\n",
    "plt.show()\n",
    "\n",
    "numWords=[]\n",
    "for item in cleaned_real_text2_train:\n",
    "    numWords.append(len(item))\n",
    "\n",
    "plt.hist(numWords, bins=400)\n",
    "plt.xlabel('train real text2 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 75])\n",
    "plt.show()\n",
    "\n",
    "numWords=[]\n",
    "for item in cleaned_real_text1_test:\n",
    "    numWords.append(len(item))\n",
    "\n",
    "plt.hist(numWords, bins=400)\n",
    "plt.xlabel('test real text1 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 75])\n",
    "plt.show()\n",
    "\n",
    "numWords=[]\n",
    "for item in cleaned_real_text2_test:\n",
    "    numWords.append(len(item))\n",
    "\n",
    "plt.hist(numWords, bins=400)\n",
    "plt.xlabel('test real text2 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 75])\n",
    "plt.show()\n",
    "\n",
    "numWords=[]\n",
    "for item in cleaned_fake_text1_train:\n",
    "    numWords.append(len(item))\n",
    "\n",
    "plt.hist(numWords, bins=400)\n",
    "plt.xlabel('train fake text1 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 150])\n",
    "plt.show()\n",
    "\n",
    "numWords=[]\n",
    "for item in cleaned_fake_text2_train:\n",
    "    numWords.append(len(item))\n",
    "\n",
    "plt.hist(numWords, bins=400)\n",
    "plt.xlabel('train fake text2 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 150])\n",
    "plt.show()\n",
    "\n",
    "numWords=[]\n",
    "for item in cleaned_fake_text1_test:\n",
    "    numWords.append(len(item))\n",
    "\n",
    "plt.hist(numWords, bins=400)\n",
    "plt.xlabel('test fake text1 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 150])\n",
    "plt.show()\n",
    "\n",
    "numWords=[]\n",
    "for item in cleaned_fake_text2_test:\n",
    "    numWords.append(len(item))\n",
    "\n",
    "plt.hist(numWords, bins=400)\n",
    "plt.xlabel('test fake text2 Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1000, 0, 150])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the word list!\n",
      "Loaded the word vectors!\n",
      "400000\n",
      "(400000, 50)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "wordsList = np.load('./data/wordsList.npy')\n",
    "print('Loaded the word list!')\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load('./data/wordVectors.npy')\n",
    "print ('Loaded the word vectors!')\n",
    "print(len(wordsList))\n",
    "print(wordVectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids_real_text1_train over\n",
      "ids_fake_text1_train over\n",
      "ids_real_text1_test over\n",
      "ids_fake_text1_test over\n"
     ]
    }
   ],
   "source": [
    "#text1 section\n",
    "text1_maxSeqLength = 200\n",
    "\n",
    "ids_real_text1_train = np.zeros((len(cleaned_real_text1_train), text1_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for text1 in cleaned_real_text1_train:\n",
    "    indexCounter = 0\n",
    "    for word in text1:\n",
    "        try:\n",
    "            ids_real_text1_train[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_real_text1_train[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= text1_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    if fileCounter%10000==0:\n",
    "        print(fileCounter)\n",
    "\n",
    "np.save('data/idsMatrix_real_text1_train', ids_real_text1_train)\n",
    "print(\"ids_real_text1_train over\")\n",
    "\n",
    "ids_fake_text1_train = np.zeros((len(cleaned_fake_text1_train), text1_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for text1 in cleaned_fake_text1_train:\n",
    "    indexCounter = 0\n",
    "    for word in text1:\n",
    "        try:\n",
    "            ids_fake_text1_train[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_fake_text1_train[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= text1_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "\n",
    "np.save('data/idsMatrix_fake_text1_train', ids_fake_text1_train)\n",
    "print(\"ids_fake_text1_train over\")\n",
    "\n",
    "ids_real_text1_test = np.zeros((len(cleaned_real_text1_test), text1_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for text1 in cleaned_real_text1_test:\n",
    "    indexCounter = 0\n",
    "    for word in text1:\n",
    "        try:\n",
    "            ids_real_text1_test[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_real_text1_test[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= text1_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    \n",
    "\n",
    "np.save('data/idsMatrix_real_text1_test', ids_real_text1_test)\n",
    "print(\"ids_real_text1_test over\")\n",
    "\n",
    "ids_fake_text1_test = np.zeros((len(cleaned_fake_text1_test), text1_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for text1 in cleaned_fake_text1_test:\n",
    "    indexCounter = 0\n",
    "    for word in text1:\n",
    "        try:\n",
    "            ids_fake_text1_test[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_fake_text1_test[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= text1_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    \n",
    "\n",
    "np.save('data/idsMatrix_fake_text1_test', ids_fake_text1_test)\n",
    "print(\"ids_fake_text1_test over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids_real_text2_train over\n",
      "ids_fake_text2_train over\n",
      "ids_real_text2_test over\n",
      "ids_fake_text2_test over\n"
     ]
    }
   ],
   "source": [
    "#text2 section\n",
    "text2_maxSeqLength = 200\n",
    "\n",
    "ids_real_text2_train = np.zeros((len(cleaned_real_text2_train), text2_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for text2 in cleaned_real_text2_train:\n",
    "    indexCounter = 0\n",
    "    for word in text2:\n",
    "        try:\n",
    "            ids_real_text2_train[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_real_text2_train[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= text2_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    if fileCounter%10000==0:\n",
    "        print(fileCounter)\n",
    "\n",
    "np.save('data/idsMatrix_real_text2_train', ids_real_text2_train)\n",
    "print(\"ids_real_text2_train over\")\n",
    "\n",
    "ids_fake_text2_train = np.zeros((len(cleaned_fake_text2_train), text2_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for text2 in cleaned_fake_text2_train:\n",
    "    indexCounter = 0\n",
    "    for word in text2:\n",
    "        try:\n",
    "            ids_fake_text2_train[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_fake_text2_train[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= text2_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "\n",
    "np.save('data/idsMatrix_fake_text2_train', ids_fake_text2_train)\n",
    "print(\"ids_fake_text2_train over\")\n",
    "\n",
    "ids_real_text2_test = np.zeros((len(cleaned_real_text2_test), text2_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for text2 in cleaned_real_text2_test:\n",
    "    indexCounter = 0\n",
    "    for word in text2:\n",
    "        try:\n",
    "            ids_real_text2_test[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_real_text2_test[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= text2_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    \n",
    "\n",
    "np.save('data/idsMatrix_real_text2_test', ids_real_text2_test)\n",
    "print(\"ids_real_text2_test over\")\n",
    "\n",
    "ids_fake_text2_test = np.zeros((len(cleaned_fake_text2_test), text2_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for text2 in cleaned_fake_text2_test:\n",
    "    indexCounter = 0\n",
    "    for word in text2:\n",
    "        try:\n",
    "            ids_fake_text2_test[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_fake_text2_test[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= text2_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    \n",
    "\n",
    "np.save('data/idsMatrix_fake_text2_test', ids_fake_text2_test)\n",
    "print(\"ids_fake_text2_test over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids_real_title_train over\n",
      "ids_fake_title_train over\n",
      "ids_real_title_test over\n",
      "ids_fake_title_test over\n"
     ]
    }
   ],
   "source": [
    "'''#title section\n",
    "title_maxSeqLength = 20\n",
    "\n",
    "ids_real_title_train = np.zeros((len(cleaned_real_title_train), title_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for title in cleaned_real_title_train:\n",
    "    indexCounter = 0\n",
    "    for word in title:\n",
    "        try:\n",
    "            ids_real_title_train[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_real_title_train[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= title_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    if fileCounter%10000==0:\n",
    "        print(fileCounter)\n",
    "\n",
    "np.save('data/idsMatrix_real_title_train', ids_real_title_train)\n",
    "print(\"ids_real_title_train over\")\n",
    "\n",
    "ids_fake_title_train = np.zeros((len(cleaned_fake_title_train), title_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for title in cleaned_fake_title_train:\n",
    "    indexCounter = 0\n",
    "    for word in title:\n",
    "        try:\n",
    "            ids_fake_title_train[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_fake_title_train[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= title_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "\n",
    "np.save('data/idsMatrix_fake_title_train', ids_fake_title_train)\n",
    "print(\"ids_fake_title_train over\")\n",
    "\n",
    "ids_real_title_test = np.zeros((len(cleaned_real_title_test), title_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for title in cleaned_real_title_test:\n",
    "    indexCounter = 0\n",
    "    for word in title:\n",
    "        try:\n",
    "            ids_real_title_test[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_real_title_test[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= title_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    \n",
    "\n",
    "np.save('data/idsMatrix_real_title_test', ids_real_title_test)\n",
    "print(\"ids_real_title_test over\")\n",
    "\n",
    "ids_fake_title_test = np.zeros((len(cleaned_fake_title_test), title_maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for title in cleaned_fake_title_test:\n",
    "    indexCounter = 0\n",
    "    for word in title:\n",
    "        try:\n",
    "            ids_fake_title_test[fileCounter][indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            ids_fake_title_test[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= title_maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "    \n",
    "\n",
    "np.save('data/idsMatrix_fake_title_test', ids_fake_title_test)\n",
    "print(\"ids_fake_title_test over\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "iteration 101/30001... loss 0.5777103304862976... accuracy 0.625...\n",
      "iteration 201/30001... loss 0.7567188143730164... accuracy 0.5833333134651184...\n",
      "iteration 301/30001... loss 0.8028159737586975... accuracy 0.5416666865348816...\n",
      "iteration 401/30001... loss 0.7102668881416321... accuracy 0.7083333134651184...\n",
      "iteration 501/30001... loss 0.5369760394096375... accuracy 0.75...\n",
      "iteration 601/30001... loss 0.49449291825294495... accuracy 0.7916666865348816...\n",
      "iteration 701/30001... loss 0.9400654435157776... accuracy 0.5833333134651184...\n",
      "iteration 801/30001... loss 0.40664276480674744... accuracy 0.75...\n",
      "iteration 901/30001... loss 0.7969688773155212... accuracy 0.7083333134651184...\n",
      "iteration 1001/30001... loss 0.40833306312561035... accuracy 0.7083333134651184...\n",
      "iteration 1101/30001... loss 0.5458244681358337... accuracy 0.625...\n",
      "iteration 1201/30001... loss 0.5157278180122375... accuracy 0.7083333134651184...\n",
      "iteration 1301/30001... loss 0.5915770530700684... accuracy 0.6666666865348816...\n",
      "iteration 1401/30001... loss 0.4870668351650238... accuracy 0.75...\n",
      "iteration 1501/30001... loss 0.3471585214138031... accuracy 0.7916666865348816...\n",
      "iteration 1601/30001... loss 0.500566303730011... accuracy 0.7083333134651184...\n",
      "iteration 1701/30001... loss 0.5527748465538025... accuracy 0.7083333134651184...\n",
      "iteration 1801/30001... loss 0.5558663010597229... accuracy 0.75...\n",
      "iteration 1901/30001... loss 0.4273192584514618... accuracy 0.7916666865348816...\n",
      "iteration 2001/30001... loss 0.48433247208595276... accuracy 0.75...\n",
      "iteration 2101/30001... loss 0.4463346302509308... accuracy 0.7083333134651184...\n",
      "iteration 2201/30001... loss 0.5252272486686707... accuracy 0.8333333134651184...\n",
      "iteration 2301/30001... loss 0.3363119065761566... accuracy 0.875...\n",
      "iteration 2401/30001... loss 0.2685061991214752... accuracy 0.9166666865348816...\n",
      "iteration 2501/30001... loss 0.44257912039756775... accuracy 0.75...\n",
      "iteration 2601/30001... loss 0.32094642519950867... accuracy 0.7916666865348816...\n",
      "iteration 2701/30001... loss 0.386017769575119... accuracy 0.7083333134651184...\n",
      "iteration 2801/30001... loss 0.1663820594549179... accuracy 0.9166666865348816...\n",
      "iteration 2901/30001... loss 0.40741443634033203... accuracy 0.7916666865348816...\n",
      "iteration 3001/30001... loss 0.24744029343128204... accuracy 0.9166666865348816...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-3000\n",
      "iteration 3101/30001... loss 0.3041202425956726... accuracy 0.7916666865348816...\n",
      "iteration 3201/30001... loss 0.2990942895412445... accuracy 0.7916666865348816...\n",
      "iteration 3301/30001... loss 0.4248189926147461... accuracy 0.7916666865348816...\n",
      "iteration 3401/30001... loss 0.37177133560180664... accuracy 0.7916666865348816...\n",
      "iteration 3501/30001... loss 0.4328122138977051... accuracy 0.7916666865348816...\n",
      "iteration 3601/30001... loss 0.6329857707023621... accuracy 0.6666666865348816...\n",
      "iteration 3701/30001... loss 0.5760273337364197... accuracy 0.75...\n",
      "iteration 3801/30001... loss 0.5896169543266296... accuracy 0.75...\n",
      "iteration 3901/30001... loss 0.1860843449831009... accuracy 1.0...\n",
      "iteration 4001/30001... loss 0.5661628842353821... accuracy 0.75...\n",
      "iteration 4101/30001... loss 0.42818889021873474... accuracy 0.75...\n",
      "iteration 4201/30001... loss 0.18893171846866608... accuracy 0.9583333134651184...\n",
      "iteration 4301/30001... loss 0.4305935204029083... accuracy 0.8333333134651184...\n",
      "iteration 4401/30001... loss 0.254402756690979... accuracy 0.9166666865348816...\n",
      "iteration 4501/30001... loss 0.1949482411146164... accuracy 0.9166666865348816...\n",
      "iteration 4601/30001... loss 0.30923786759376526... accuracy 0.875...\n",
      "iteration 4701/30001... loss 0.34380221366882324... accuracy 0.875...\n",
      "iteration 4801/30001... loss 0.23466943204402924... accuracy 0.9583333134651184...\n",
      "iteration 4901/30001... loss 0.34510454535484314... accuracy 0.875...\n",
      "iteration 5001/30001... loss 0.1154731884598732... accuracy 1.0...\n",
      "iteration 5101/30001... loss 0.23716603219509125... accuracy 0.9166666865348816...\n",
      "iteration 5201/30001... loss 0.25757279992103577... accuracy 0.9166666865348816...\n",
      "iteration 5301/30001... loss 0.16668415069580078... accuracy 0.875...\n",
      "iteration 5401/30001... loss 0.23036377131938934... accuracy 0.9583333134651184...\n",
      "iteration 5501/30001... loss 0.12964056432247162... accuracy 0.9583333134651184...\n",
      "iteration 5601/30001... loss 0.19686554372310638... accuracy 0.9166666865348816...\n",
      "iteration 5701/30001... loss 0.3269525170326233... accuracy 0.7916666865348816...\n",
      "iteration 5801/30001... loss 0.24090497195720673... accuracy 0.9166666865348816...\n",
      "iteration 5901/30001... loss 0.14831753075122833... accuracy 0.9166666865348816...\n",
      "iteration 6001/30001... loss 0.1712787002325058... accuracy 0.9166666865348816...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-6000\n",
      "iteration 6101/30001... loss 0.06693557649850845... accuracy 1.0...\n",
      "iteration 6201/30001... loss 0.09434936195611954... accuracy 0.9583333134651184...\n",
      "iteration 6301/30001... loss 0.3616325557231903... accuracy 0.875...\n",
      "iteration 6401/30001... loss 0.062478333711624146... accuracy 1.0...\n",
      "iteration 6501/30001... loss 0.36481866240501404... accuracy 0.8333333134651184...\n",
      "iteration 6601/30001... loss 0.17126290500164032... accuracy 0.9166666865348816...\n",
      "iteration 6701/30001... loss 0.3314119875431061... accuracy 0.875...\n",
      "iteration 6801/30001... loss 0.25516486167907715... accuracy 0.9166666865348816...\n",
      "iteration 6901/30001... loss 0.2540779113769531... accuracy 0.9166666865348816...\n",
      "iteration 7001/30001... loss 0.22035272419452667... accuracy 0.8333333134651184...\n",
      "iteration 7101/30001... loss 0.3107633888721466... accuracy 0.9166666865348816...\n",
      "iteration 7201/30001... loss 0.20424962043762207... accuracy 0.875...\n",
      "iteration 7301/30001... loss 0.019754817709326744... accuracy 1.0...\n",
      "iteration 7401/30001... loss 0.2125440239906311... accuracy 1.0...\n",
      "iteration 7501/30001... loss 0.3100287914276123... accuracy 0.875...\n",
      "iteration 7601/30001... loss 0.30759039521217346... accuracy 0.875...\n",
      "iteration 7701/30001... loss 0.2920492887496948... accuracy 0.9166666865348816...\n",
      "iteration 7801/30001... loss 0.2324775904417038... accuracy 0.875...\n",
      "iteration 7901/30001... loss 0.21919207274913788... accuracy 0.9166666865348816...\n",
      "iteration 8001/30001... loss 0.34586814045906067... accuracy 0.875...\n",
      "iteration 8101/30001... loss 0.24720050394535065... accuracy 0.9166666865348816...\n",
      "iteration 8201/30001... loss 0.15161024034023285... accuracy 0.9583333134651184...\n",
      "iteration 8301/30001... loss 0.47703853249549866... accuracy 0.8333333134651184...\n",
      "iteration 8401/30001... loss 0.14016826450824738... accuracy 0.9583333134651184...\n",
      "iteration 8501/30001... loss 0.050195056945085526... accuracy 0.9583333134651184...\n",
      "iteration 8601/30001... loss 0.16834606230258942... accuracy 0.9583333134651184...\n",
      "iteration 8701/30001... loss 0.2776474058628082... accuracy 0.9583333134651184...\n",
      "iteration 8801/30001... loss 0.06525100022554398... accuracy 1.0...\n",
      "iteration 8901/30001... loss 0.029270315542817116... accuracy 1.0...\n",
      "iteration 9001/30001... loss 0.11207679659128189... accuracy 0.9583333134651184...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-9000\n",
      "iteration 9101/30001... loss 0.054375991225242615... accuracy 1.0...\n",
      "iteration 9201/30001... loss 0.07418898493051529... accuracy 0.9583333134651184...\n",
      "iteration 9301/30001... loss 1.4148507118225098... accuracy 0.625...\n",
      "iteration 9401/30001... loss 1.1996098756790161... accuracy 0.7083333134651184...\n",
      "iteration 9501/30001... loss 1.4214569330215454... accuracy 0.4583333432674408...\n",
      "iteration 9601/30001... loss 0.29383131861686707... accuracy 0.7916666865348816...\n",
      "iteration 9701/30001... loss 0.5327939391136169... accuracy 0.7916666865348816...\n",
      "iteration 9801/30001... loss 0.2997846305370331... accuracy 0.875...\n",
      "iteration 9901/30001... loss 0.6259222626686096... accuracy 0.6666666865348816...\n",
      "iteration 10001/30001... loss 0.5498778820037842... accuracy 0.7916666865348816...\n",
      "iteration 10101/30001... loss 0.14388637244701385... accuracy 1.0...\n",
      "iteration 10201/30001... loss 0.2170783132314682... accuracy 0.9166666865348816...\n",
      "iteration 10301/30001... loss 0.35263022780418396... accuracy 0.8333333134651184...\n",
      "iteration 10401/30001... loss 0.1420261412858963... accuracy 0.9166666865348816...\n",
      "iteration 10501/30001... loss 0.10278622061014175... accuracy 1.0...\n",
      "iteration 10601/30001... loss 0.22584962844848633... accuracy 0.9166666865348816...\n",
      "iteration 10701/30001... loss 0.27297356724739075... accuracy 0.9166666865348816...\n",
      "iteration 10801/30001... loss 0.329607754945755... accuracy 0.7916666865348816...\n",
      "iteration 10901/30001... loss 0.07099973410367966... accuracy 0.9583333134651184...\n",
      "iteration 11001/30001... loss 0.15421974658966064... accuracy 0.9166666865348816...\n",
      "iteration 11101/30001... loss 0.17111343145370483... accuracy 0.9583333134651184...\n",
      "iteration 11201/30001... loss 0.12173544615507126... accuracy 0.9583333134651184...\n",
      "iteration 11301/30001... loss 0.09907452017068863... accuracy 0.9583333134651184...\n",
      "iteration 11401/30001... loss 0.07140638679265976... accuracy 0.9583333134651184...\n",
      "iteration 11501/30001... loss 0.3247741162776947... accuracy 0.9166666865348816...\n",
      "iteration 11601/30001... loss 0.05694514140486717... accuracy 1.0...\n",
      "iteration 11701/30001... loss 0.07953561842441559... accuracy 0.9583333134651184...\n",
      "iteration 11801/30001... loss 0.21328742802143097... accuracy 0.9166666865348816...\n",
      "iteration 11901/30001... loss 0.31417417526245117... accuracy 0.9166666865348816...\n",
      "iteration 12001/30001... loss 0.15731140971183777... accuracy 0.9583333134651184...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-12000\n",
      "iteration 12101/30001... loss 0.15126723051071167... accuracy 0.9166666865348816...\n",
      "iteration 12201/30001... loss 0.4062250852584839... accuracy 0.8333333134651184...\n",
      "iteration 12301/30001... loss 0.11108481884002686... accuracy 0.9166666865348816...\n",
      "iteration 12401/30001... loss 0.04241357743740082... accuracy 1.0...\n",
      "iteration 12501/30001... loss 0.11141461133956909... accuracy 0.9583333134651184...\n",
      "iteration 12601/30001... loss 0.04254372790455818... accuracy 1.0...\n",
      "iteration 12701/30001... loss 0.030045947059988976... accuracy 1.0...\n",
      "iteration 12801/30001... loss 0.031119853258132935... accuracy 1.0...\n",
      "iteration 12901/30001... loss 0.042638927698135376... accuracy 0.9583333134651184...\n",
      "iteration 13001/30001... loss 0.022204214707016945... accuracy 1.0...\n",
      "iteration 13101/30001... loss 0.24535028636455536... accuracy 0.9583333134651184...\n",
      "iteration 13201/30001... loss 0.008619513362646103... accuracy 1.0...\n",
      "iteration 13301/30001... loss 0.026916323229670525... accuracy 1.0...\n",
      "iteration 13401/30001... loss 0.09180405735969543... accuracy 0.9583333134651184...\n",
      "iteration 13501/30001... loss 0.1049429178237915... accuracy 0.9583333134651184...\n",
      "iteration 13601/30001... loss 0.3308716416358948... accuracy 0.9583333134651184...\n",
      "iteration 13701/30001... loss 0.17970804870128632... accuracy 0.9166666865348816...\n",
      "iteration 13801/30001... loss 0.047747790813446045... accuracy 0.9583333134651184...\n",
      "iteration 13901/30001... loss 0.027028262615203857... accuracy 1.0...\n",
      "iteration 14001/30001... loss 0.20231859385967255... accuracy 0.875...\n",
      "iteration 14101/30001... loss 0.006492968183010817... accuracy 1.0...\n",
      "iteration 14201/30001... loss 0.13322140276432037... accuracy 0.9583333134651184...\n",
      "iteration 14301/30001... loss 0.0170421302318573... accuracy 1.0...\n",
      "iteration 14401/30001... loss 0.03153914958238602... accuracy 1.0...\n",
      "iteration 14501/30001... loss 0.10139574855566025... accuracy 0.9583333134651184...\n",
      "iteration 14601/30001... loss 0.034877482801675797... accuracy 1.0...\n",
      "iteration 14701/30001... loss 0.030604297295212746... accuracy 1.0...\n",
      "iteration 14801/30001... loss 0.04946252703666687... accuracy 1.0...\n",
      "iteration 14901/30001... loss 0.07075662165880203... accuracy 0.9583333134651184...\n",
      "iteration 15001/30001... loss 0.02224157191812992... accuracy 1.0...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-15000\n",
      "iteration 15101/30001... loss 0.0009730488527566195... accuracy 1.0...\n",
      "iteration 15201/30001... loss 0.003915170207619667... accuracy 1.0...\n",
      "iteration 15301/30001... loss 0.07849600166082382... accuracy 0.9583333134651184...\n",
      "iteration 15401/30001... loss 0.021507563069462776... accuracy 1.0...\n",
      "iteration 15501/30001... loss 0.13520298898220062... accuracy 0.9166666865348816...\n",
      "iteration 15601/30001... loss 0.006102836225181818... accuracy 1.0...\n",
      "iteration 15701/30001... loss 0.035213056951761246... accuracy 1.0...\n",
      "iteration 15801/30001... loss 0.04618871212005615... accuracy 0.9583333134651184...\n",
      "iteration 15901/30001... loss 0.014022886753082275... accuracy 1.0...\n",
      "iteration 16001/30001... loss 0.0017049513990059495... accuracy 1.0...\n",
      "iteration 16101/30001... loss 0.018664171919226646... accuracy 1.0...\n",
      "iteration 16201/30001... loss 0.005595704074949026... accuracy 1.0...\n",
      "iteration 16301/30001... loss 0.02706865780055523... accuracy 1.0...\n",
      "iteration 16401/30001... loss 0.011796983890235424... accuracy 1.0...\n",
      "iteration 16501/30001... loss 0.00721608055755496... accuracy 1.0...\n",
      "iteration 16601/30001... loss 0.05409255251288414... accuracy 0.9583333134651184...\n",
      "iteration 16701/30001... loss 0.03851477801799774... accuracy 1.0...\n",
      "iteration 16801/30001... loss 0.003308067796751857... accuracy 1.0...\n",
      "iteration 16901/30001... loss 0.01592901349067688... accuracy 1.0...\n",
      "iteration 17001/30001... loss 0.033396970480680466... accuracy 1.0...\n",
      "iteration 17101/30001... loss 0.06832439452409744... accuracy 0.9583333134651184...\n",
      "iteration 17201/30001... loss 0.04204567149281502... accuracy 1.0...\n",
      "iteration 17301/30001... loss 0.00850145984441042... accuracy 1.0...\n",
      "iteration 17401/30001... loss 0.010111183859407902... accuracy 1.0...\n",
      "iteration 17501/30001... loss 0.20778626203536987... accuracy 0.875...\n",
      "iteration 17601/30001... loss 0.10810422897338867... accuracy 0.9583333134651184...\n",
      "iteration 17701/30001... loss 0.05021779239177704... accuracy 0.9583333134651184...\n",
      "iteration 17801/30001... loss 0.0458918958902359... accuracy 1.0...\n",
      "iteration 17901/30001... loss 0.02121702767908573... accuracy 1.0...\n",
      "iteration 18001/30001... loss 0.08433249592781067... accuracy 0.9583333134651184...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-18000\n",
      "iteration 18101/30001... loss 0.016210481524467468... accuracy 1.0...\n",
      "iteration 18201/30001... loss 0.012376605533063412... accuracy 1.0...\n",
      "iteration 18301/30001... loss 0.0045412159524858... accuracy 1.0...\n",
      "iteration 18401/30001... loss 7.166514842538163e-05... accuracy 1.0...\n",
      "iteration 18501/30001... loss 0.044685591012239456... accuracy 0.9583333134651184...\n",
      "iteration 18601/30001... loss 0.008165404200553894... accuracy 1.0...\n",
      "iteration 18701/30001... loss 0.003349112346768379... accuracy 1.0...\n",
      "iteration 18801/30001... loss 0.0403815321624279... accuracy 0.9583333134651184...\n",
      "iteration 18901/30001... loss 0.0714334174990654... accuracy 0.9583333134651184...\n",
      "iteration 19001/30001... loss 0.07165134698152542... accuracy 0.9583333134651184...\n",
      "iteration 19101/30001... loss 0.0018223182996734977... accuracy 1.0...\n",
      "iteration 19201/30001... loss 0.12327108532190323... accuracy 0.9583333134651184...\n",
      "iteration 19301/30001... loss 0.10481654852628708... accuracy 0.9166666865348816...\n",
      "iteration 19401/30001... loss 0.06316512078046799... accuracy 1.0...\n",
      "iteration 19501/30001... loss 0.00017824095266405493... accuracy 1.0...\n",
      "iteration 19601/30001... loss 0.014864142052829266... accuracy 1.0...\n",
      "iteration 19701/30001... loss 0.0668647289276123... accuracy 0.9583333134651184...\n",
      "iteration 19801/30001... loss 0.002353304298594594... accuracy 1.0...\n",
      "iteration 19901/30001... loss 0.017572158947587013... accuracy 1.0...\n",
      "iteration 20001/30001... loss 0.1378045231103897... accuracy 0.9583333134651184...\n",
      "iteration 20101/30001... loss 0.030628053471446037... accuracy 1.0...\n",
      "iteration 20201/30001... loss 0.03464028611779213... accuracy 1.0...\n",
      "iteration 20301/30001... loss 0.07645224779844284... accuracy 0.9583333134651184...\n",
      "iteration 20401/30001... loss 0.04236428812146187... accuracy 1.0...\n",
      "iteration 20501/30001... loss 0.219060018658638... accuracy 0.9166666865348816...\n",
      "iteration 20601/30001... loss 0.003820940153673291... accuracy 1.0...\n",
      "iteration 20701/30001... loss 0.017622971907258034... accuracy 1.0...\n",
      "iteration 20801/30001... loss 0.16638150811195374... accuracy 0.9166666865348816...\n",
      "iteration 20901/30001... loss 0.01577993854880333... accuracy 1.0...\n",
      "iteration 21001/30001... loss 0.005655755754560232... accuracy 1.0...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-21000\n",
      "iteration 21101/30001... loss 0.007418740075081587... accuracy 1.0...\n",
      "iteration 21201/30001... loss 0.0021480864379554987... accuracy 1.0...\n",
      "iteration 21301/30001... loss 0.06444006413221359... accuracy 0.9583333134651184...\n",
      "iteration 21401/30001... loss 0.020669670775532722... accuracy 1.0...\n",
      "iteration 21501/30001... loss 0.06424801051616669... accuracy 0.9583333134651184...\n",
      "iteration 21601/30001... loss 0.0024645812809467316... accuracy 1.0...\n",
      "iteration 21701/30001... loss 0.03516588732600212... accuracy 1.0...\n",
      "iteration 21801/30001... loss 0.007114255800843239... accuracy 1.0...\n",
      "iteration 21901/30001... loss 0.006375150289386511... accuracy 1.0...\n",
      "iteration 22001/30001... loss 0.01774638704955578... accuracy 1.0...\n",
      "iteration 22101/30001... loss 0.016769858077168465... accuracy 1.0...\n",
      "iteration 22201/30001... loss 4.855574297835119e-05... accuracy 1.0...\n",
      "iteration 22301/30001... loss 0.029256803914904594... accuracy 1.0...\n",
      "iteration 22401/30001... loss 0.036351315677165985... accuracy 0.9583333134651184...\n",
      "iteration 22501/30001... loss 0.10098057985305786... accuracy 0.9583333134651184...\n",
      "iteration 22601/30001... loss 0.066355861723423... accuracy 0.9583333134651184...\n",
      "iteration 22701/30001... loss 0.004723380785435438... accuracy 1.0...\n",
      "iteration 22801/30001... loss 0.07199489325284958... accuracy 0.9583333134651184...\n",
      "iteration 22901/30001... loss 0.03179856762290001... accuracy 1.0...\n",
      "iteration 23001/30001... loss 0.011328433640301228... accuracy 1.0...\n",
      "iteration 23101/30001... loss 0.06628076732158661... accuracy 0.9583333134651184...\n",
      "iteration 23201/30001... loss 0.011409376747906208... accuracy 1.0...\n",
      "iteration 23301/30001... loss 0.023581957444548607... accuracy 1.0...\n",
      "iteration 23401/30001... loss 0.011041488498449326... accuracy 1.0...\n",
      "iteration 23501/30001... loss 0.10353964567184448... accuracy 0.9583333134651184...\n",
      "iteration 23601/30001... loss 0.09436448663473129... accuracy 0.9583333134651184...\n",
      "iteration 23701/30001... loss 0.08434777706861496... accuracy 1.0...\n",
      "iteration 23801/30001... loss 0.23207958042621613... accuracy 1.0...\n",
      "iteration 23901/30001... loss 0.0035909030120819807... accuracy 1.0...\n",
      "iteration 24001/30001... loss 0.00505065219476819... accuracy 1.0...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-24000\n",
      "iteration 24101/30001... loss 0.014585442841053009... accuracy 1.0...\n",
      "iteration 24201/30001... loss 0.011812693439424038... accuracy 1.0...\n",
      "iteration 24301/30001... loss 0.01456046849489212... accuracy 1.0...\n",
      "iteration 24401/30001... loss 0.08683889359235764... accuracy 0.9583333134651184...\n",
      "iteration 24501/30001... loss 0.0004234518564771861... accuracy 1.0...\n",
      "iteration 24601/30001... loss 0.00039240383193828166... accuracy 1.0...\n",
      "iteration 24701/30001... loss 0.15143156051635742... accuracy 0.9166666865348816...\n",
      "iteration 24801/30001... loss 0.0007896521710790694... accuracy 1.0...\n",
      "iteration 24901/30001... loss 0.017836911603808403... accuracy 1.0...\n",
      "iteration 25001/30001... loss 0.000190718041267246... accuracy 1.0...\n",
      "iteration 25101/30001... loss 0.0003273249894846231... accuracy 1.0...\n",
      "iteration 25201/30001... loss 0.013412565924227238... accuracy 1.0...\n",
      "iteration 25301/30001... loss 0.008567221462726593... accuracy 1.0...\n",
      "iteration 25401/30001... loss 0.055490877479314804... accuracy 0.9583333134651184...\n",
      "iteration 25501/30001... loss 0.02608361653983593... accuracy 1.0...\n",
      "iteration 25601/30001... loss 0.01644059270620346... accuracy 1.0...\n",
      "iteration 25701/30001... loss 2.9426882974803448e-05... accuracy 1.0...\n",
      "iteration 25801/30001... loss 0.013992750085890293... accuracy 1.0...\n",
      "iteration 25901/30001... loss 0.007266394793987274... accuracy 1.0...\n",
      "iteration 26001/30001... loss 0.013271268457174301... accuracy 1.0...\n",
      "iteration 26101/30001... loss 5.25613286299631e-05... accuracy 1.0...\n",
      "iteration 26201/30001... loss 0.015451464802026749... accuracy 1.0...\n",
      "iteration 26301/30001... loss 0.0183839313685894... accuracy 1.0...\n",
      "iteration 26401/30001... loss 0.0005813950556330383... accuracy 1.0...\n",
      "iteration 26501/30001... loss 0.015682151541113853... accuracy 1.0...\n",
      "iteration 26601/30001... loss 0.0005442981491796672... accuracy 1.0...\n",
      "iteration 26701/30001... loss 0.012282454408705235... accuracy 1.0...\n",
      "iteration 26801/30001... loss 0.00028461823239922523... accuracy 1.0...\n",
      "iteration 26901/30001... loss 0.02239982783794403... accuracy 1.0...\n",
      "iteration 27001/30001... loss 0.0119112404063344... accuracy 1.0...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-27000\n",
      "iteration 27101/30001... loss 0.0529571957886219... accuracy 0.9583333134651184...\n",
      "iteration 27201/30001... loss 5.725890878238715e-05... accuracy 1.0...\n",
      "iteration 27301/30001... loss 0.024829545989632607... accuracy 1.0...\n",
      "iteration 27401/30001... loss 0.020585164427757263... accuracy 1.0...\n",
      "iteration 27501/30001... loss 0.08111006766557693... accuracy 0.9583333134651184...\n",
      "iteration 27601/30001... loss 0.0025956991594284773... accuracy 1.0...\n",
      "iteration 27701/30001... loss 0.02020413801074028... accuracy 1.0...\n",
      "iteration 27801/30001... loss 0.008919117040932178... accuracy 1.0...\n",
      "iteration 27901/30001... loss 0.0034164099488407373... accuracy 1.0...\n",
      "iteration 28001/30001... loss 0.06517733633518219... accuracy 1.0...\n",
      "iteration 28101/30001... loss 0.0031757864635437727... accuracy 1.0...\n",
      "iteration 28201/30001... loss 0.0003660651564132422... accuracy 1.0...\n",
      "iteration 28301/30001... loss 0.06587359309196472... accuracy 0.9583333134651184...\n",
      "iteration 28401/30001... loss 0.0005713196005672216... accuracy 1.0...\n",
      "iteration 28501/30001... loss 0.16370876133441925... accuracy 0.875...\n",
      "iteration 28601/30001... loss 0.0230314489454031... accuracy 1.0...\n",
      "iteration 28701/30001... loss 8.270747639471665e-05... accuracy 1.0...\n",
      "iteration 28801/30001... loss 0.06452512741088867... accuracy 0.9583333134651184...\n",
      "iteration 28901/30001... loss 8.25575043563731e-05... accuracy 1.0...\n",
      "iteration 29001/30001... loss 0.05840536579489708... accuracy 0.9583333134651184...\n",
      "iteration 29101/30001... loss 0.031385388225317... accuracy 1.0...\n",
      "iteration 29201/30001... loss 0.0927264615893364... accuracy 0.9583333134651184...\n",
      "iteration 29301/30001... loss 0.026260562241077423... accuracy 1.0...\n",
      "iteration 29401/30001... loss 0.08175856620073318... accuracy 1.0...\n",
      "iteration 29501/30001... loss 0.07049817591905594... accuracy 0.9583333134651184...\n",
      "iteration 29601/30001... loss 7.013014692347497e-05... accuracy 1.0...\n",
      "iteration 29701/30001... loss 0.009002204053103924... accuracy 1.0...\n",
      "iteration 29801/30001... loss 0.017249060794711113... accuracy 1.0...\n",
      "iteration 29901/30001... loss 0.0108957439661026... accuracy 1.0...\n",
      "iteration 30001/30001... loss 0.004581426735967398... accuracy 1.0...\n",
      "saved to text_divide_models/pretrained_lstm.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "#text_section\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "\n",
    "ids_real_text1_train = np.load('data/idsMatrix_real_text1_train.npy')\n",
    "ids_fake_text1_train = np.load('data/idsMatrix_fake_text1_train.npy')\n",
    "\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, text_maxSeqLength])\n",
    "    #一半取正标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_fake_text1_train)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_text1_train[num-1:num]\n",
    "    #一半取负标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_real_text1_train)-1)\n",
    "        labels.append([0,1])\n",
    "        arr[int(batchSize/2)+i] = ids_real_text1_train[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "\n",
    "batchSize = 24\n",
    "lstmUnits = 256\n",
    "numClasses = 2\n",
    "iterations = 30001\n",
    "text_maxSeqLength = 200\n",
    "numDimensions = 50 \n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, text_maxSeqLength])\n",
    "\n",
    "data = tf.Variable(tf.zeros([batchSize, text_maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "#取最终的结果值\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(1)\n",
    "for i in range(iterations):\n",
    "    #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels}) \n",
    "    if i==0:\n",
    "        print(2)\n",
    "    if (i % 100 == 0 and i != 0):\n",
    "        loss_ = sess.run(loss, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        accuracy_ = sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        \n",
    "        \n",
    "        print(\"iteration {}/{}...\".format(i+1, iterations),\n",
    "              \"loss {}...\".format(loss_),\n",
    "              \"accuracy {}...\".format(accuracy_))\n",
    "    #Save the network every 10,000 training iterations\n",
    "    if (i % 3000 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"text_divide_models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "iteration 101/30001... loss 0.5075064301490784... accuracy 0.6666666865348816...\n",
      "iteration 201/30001... loss 0.6367958784103394... accuracy 0.6666666865348816...\n",
      "iteration 301/30001... loss 0.7685679793357849... accuracy 0.6666666865348816...\n",
      "iteration 401/30001... loss 0.48888906836509705... accuracy 0.7083333134651184...\n",
      "iteration 501/30001... loss 0.818228542804718... accuracy 0.5833333134651184...\n",
      "iteration 601/30001... loss 0.7159445285797119... accuracy 0.5416666865348816...\n",
      "iteration 701/30001... loss 0.4004894196987152... accuracy 0.6666666865348816...\n",
      "iteration 801/30001... loss 0.7067920565605164... accuracy 0.7083333134651184...\n",
      "iteration 901/30001... loss 0.6246304512023926... accuracy 0.625...\n",
      "iteration 1001/30001... loss 0.39893636107444763... accuracy 0.9166666865348816...\n",
      "iteration 1101/30001... loss 0.7042779922485352... accuracy 0.5833333134651184...\n",
      "iteration 1201/30001... loss 0.584904134273529... accuracy 0.7083333134651184...\n",
      "iteration 1301/30001... loss 0.46052607893943787... accuracy 0.8333333134651184...\n",
      "iteration 1401/30001... loss 0.5814443230628967... accuracy 0.8333333134651184...\n",
      "iteration 1501/30001... loss 0.5460404753684998... accuracy 0.7916666865348816...\n",
      "iteration 1601/30001... loss 0.4856991469860077... accuracy 0.875...\n",
      "iteration 1701/30001... loss 0.5886210799217224... accuracy 0.6666666865348816...\n",
      "iteration 1801/30001... loss 0.5001323819160461... accuracy 0.7916666865348816...\n",
      "iteration 1901/30001... loss 0.30694738030433655... accuracy 0.6666666865348816...\n",
      "iteration 2001/30001... loss 0.6048220992088318... accuracy 0.625...\n",
      "iteration 2101/30001... loss 0.5393709540367126... accuracy 0.7083333134651184...\n",
      "iteration 2201/30001... loss 0.4861750602722168... accuracy 0.7916666865348816...\n",
      "iteration 2301/30001... loss 0.5169380307197571... accuracy 0.7083333134651184...\n",
      "iteration 2401/30001... loss 0.39723777770996094... accuracy 0.875...\n",
      "iteration 2501/30001... loss 0.3617394268512726... accuracy 0.8333333134651184...\n",
      "iteration 2601/30001... loss 0.4808971881866455... accuracy 0.7916666865348816...\n",
      "iteration 2701/30001... loss 0.3262040317058563... accuracy 0.9166666865348816...\n",
      "iteration 2801/30001... loss 0.4095195531845093... accuracy 0.7916666865348816...\n",
      "iteration 2901/30001... loss 0.38081517815589905... accuracy 0.7916666865348816...\n",
      "iteration 3001/30001... loss 0.5387335419654846... accuracy 0.75...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-3000\n",
      "iteration 3101/30001... loss 0.3203784227371216... accuracy 0.8333333134651184...\n",
      "iteration 3201/30001... loss 0.4076721668243408... accuracy 0.75...\n",
      "iteration 3301/30001... loss 0.19853131473064423... accuracy 0.9166666865348816...\n",
      "iteration 3401/30001... loss 0.4310134947299957... accuracy 0.7916666865348816...\n",
      "iteration 3501/30001... loss 0.10409226268529892... accuracy 1.0...\n",
      "iteration 3601/30001... loss 0.2300388664007187... accuracy 0.9166666865348816...\n",
      "iteration 3701/30001... loss 0.24985159933567047... accuracy 0.9583333134651184...\n",
      "iteration 3801/30001... loss 0.14685362577438354... accuracy 0.9166666865348816...\n",
      "iteration 3901/30001... loss 0.164861261844635... accuracy 0.9583333134651184...\n",
      "iteration 4001/30001... loss 0.17896316945552826... accuracy 0.875...\n",
      "iteration 4101/30001... loss 0.15685342252254486... accuracy 0.9166666865348816...\n",
      "iteration 4201/30001... loss 0.28409525752067566... accuracy 0.9166666865348816...\n",
      "iteration 4301/30001... loss 0.03569101169705391... accuracy 1.0...\n",
      "iteration 4401/30001... loss 0.09490195661783218... accuracy 1.0...\n",
      "iteration 4501/30001... loss 0.1580660343170166... accuracy 0.9583333134651184...\n",
      "iteration 4601/30001... loss 0.20712196826934814... accuracy 0.9166666865348816...\n",
      "iteration 4701/30001... loss 0.22415892779827118... accuracy 0.9166666865348816...\n",
      "iteration 4801/30001... loss 0.03787010535597801... accuracy 1.0...\n",
      "iteration 4901/30001... loss 0.06998997181653976... accuracy 0.9583333134651184...\n",
      "iteration 5001/30001... loss 0.10616260021924973... accuracy 0.9166666865348816...\n",
      "iteration 5101/30001... loss 0.11310359090566635... accuracy 0.9583333134651184...\n",
      "iteration 5201/30001... loss 0.18750612437725067... accuracy 0.9583333134651184...\n",
      "iteration 5301/30001... loss 0.13378548622131348... accuracy 0.9583333134651184...\n",
      "iteration 5401/30001... loss 0.027803601697087288... accuracy 1.0...\n",
      "iteration 5501/30001... loss 0.04574305936694145... accuracy 0.9583333134651184...\n",
      "iteration 5601/30001... loss 0.058894675225019455... accuracy 1.0...\n",
      "iteration 5701/30001... loss 0.019429156556725502... accuracy 1.0...\n",
      "iteration 5801/30001... loss 0.06550353020429611... accuracy 1.0...\n",
      "iteration 5901/30001... loss 0.020550979301333427... accuracy 1.0...\n",
      "iteration 6001/30001... loss 0.018787169829010963... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-6000\n",
      "iteration 6101/30001... loss 0.06878282129764557... accuracy 0.9583333134651184...\n",
      "iteration 6201/30001... loss 0.2653786838054657... accuracy 0.875...\n",
      "iteration 6301/30001... loss 0.005005914717912674... accuracy 1.0...\n",
      "iteration 6401/30001... loss 0.0135592520236969... accuracy 1.0...\n",
      "iteration 6501/30001... loss 0.011257067322731018... accuracy 1.0...\n",
      "iteration 6601/30001... loss 0.019095459952950478... accuracy 1.0...\n",
      "iteration 6701/30001... loss 0.0069672237150371075... accuracy 1.0...\n",
      "iteration 6801/30001... loss 0.3422507047653198... accuracy 0.9583333134651184...\n",
      "iteration 6901/30001... loss 0.022036472335457802... accuracy 1.0...\n",
      "iteration 7001/30001... loss 0.004132824018597603... accuracy 1.0...\n",
      "iteration 7101/30001... loss 0.005431436467915773... accuracy 1.0...\n",
      "iteration 7201/30001... loss 0.015762336552143097... accuracy 1.0...\n",
      "iteration 7301/30001... loss 0.017387455329298973... accuracy 1.0...\n",
      "iteration 7401/30001... loss 0.04628001153469086... accuracy 1.0...\n",
      "iteration 7501/30001... loss 0.023494606837630272... accuracy 1.0...\n",
      "iteration 7601/30001... loss 0.018757252022624016... accuracy 1.0...\n",
      "iteration 7701/30001... loss 0.003964992240071297... accuracy 1.0...\n",
      "iteration 7801/30001... loss 0.011216883547604084... accuracy 1.0...\n",
      "iteration 7901/30001... loss 0.005172571167349815... accuracy 1.0...\n",
      "iteration 8001/30001... loss 0.02847086824476719... accuracy 0.9583333134651184...\n",
      "iteration 8101/30001... loss 0.003852275898680091... accuracy 1.0...\n",
      "iteration 8201/30001... loss 0.001379104913212359... accuracy 1.0...\n",
      "iteration 8301/30001... loss 0.0015111347893252969... accuracy 1.0...\n",
      "iteration 8401/30001... loss 0.0034296757075935602... accuracy 1.0...\n",
      "iteration 8501/30001... loss 0.010370967909693718... accuracy 1.0...\n",
      "iteration 8601/30001... loss 0.0015167688252404332... accuracy 1.0...\n",
      "iteration 8701/30001... loss 0.0005809665308333933... accuracy 1.0...\n",
      "iteration 8801/30001... loss 0.003976311534643173... accuracy 1.0...\n",
      "iteration 8901/30001... loss 0.00030356220668181777... accuracy 1.0...\n",
      "iteration 9001/30001... loss 0.00018119084415957332... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-9000\n",
      "iteration 9101/30001... loss 0.00013620636309497058... accuracy 1.0...\n",
      "iteration 9201/30001... loss 0.0023460702504962683... accuracy 1.0...\n",
      "iteration 9301/30001... loss 0.0069595701061189175... accuracy 1.0...\n",
      "iteration 9401/30001... loss 0.012148936279118061... accuracy 1.0...\n",
      "iteration 9501/30001... loss 0.0016392720863223076... accuracy 1.0...\n",
      "iteration 9601/30001... loss 0.007372318301349878... accuracy 1.0...\n",
      "iteration 9701/30001... loss 0.00219758041203022... accuracy 1.0...\n",
      "iteration 9801/30001... loss 0.02905920334160328... accuracy 1.0...\n",
      "iteration 9901/30001... loss 0.003975795581936836... accuracy 1.0...\n",
      "iteration 10001/30001... loss 0.013872289098799229... accuracy 1.0...\n",
      "iteration 10101/30001... loss 0.005312358494848013... accuracy 1.0...\n",
      "iteration 10201/30001... loss 0.0015459205023944378... accuracy 1.0...\n",
      "iteration 10301/30001... loss 0.0011488912859931588... accuracy 1.0...\n",
      "iteration 10401/30001... loss 0.009408175013959408... accuracy 1.0...\n",
      "iteration 10501/30001... loss 0.0032493816688656807... accuracy 1.0...\n",
      "iteration 10601/30001... loss 0.0006093570846132934... accuracy 1.0...\n",
      "iteration 10701/30001... loss 0.0011848161229863763... accuracy 1.0...\n",
      "iteration 10801/30001... loss 0.0007707591284997761... accuracy 1.0...\n",
      "iteration 10901/30001... loss 0.0008106977329589427... accuracy 0.9583333134651184...\n",
      "iteration 11001/30001... loss 0.0005089486949145794... accuracy 1.0...\n",
      "iteration 11101/30001... loss 0.0009404296870343387... accuracy 1.0...\n",
      "iteration 11201/30001... loss 0.0009981198236346245... accuracy 1.0...\n",
      "iteration 11301/30001... loss 0.0005861454992555082... accuracy 1.0...\n",
      "iteration 11401/30001... loss 0.0026559659745544195... accuracy 1.0...\n",
      "iteration 11501/30001... loss 0.0004709922068286687... accuracy 1.0...\n",
      "iteration 11601/30001... loss 0.00023211374355014414... accuracy 1.0...\n",
      "iteration 11701/30001... loss 0.0025436871219426394... accuracy 1.0...\n",
      "iteration 11801/30001... loss 0.0006600964698009193... accuracy 1.0...\n",
      "iteration 11901/30001... loss 0.0017216479172930121... accuracy 1.0...\n",
      "iteration 12001/30001... loss 0.0034460548777133226... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-12000\n",
      "iteration 12101/30001... loss 0.16622406244277954... accuracy 0.9583333134651184...\n",
      "iteration 12201/30001... loss 0.0008539958507753909... accuracy 1.0...\n",
      "iteration 12301/30001... loss 0.0009870999492704868... accuracy 1.0...\n",
      "iteration 12401/30001... loss 0.0013064555823802948... accuracy 1.0...\n",
      "iteration 12501/30001... loss 0.0010224623838439584... accuracy 1.0...\n",
      "iteration 12601/30001... loss 0.013644830323755741... accuracy 1.0...\n",
      "iteration 12701/30001... loss 0.003119844011962414... accuracy 1.0...\n",
      "iteration 12801/30001... loss 0.007426667958498001... accuracy 1.0...\n",
      "iteration 12901/30001... loss 0.0027238810434937477... accuracy 1.0...\n",
      "iteration 13001/30001... loss 9.057534771272913e-05... accuracy 1.0...\n",
      "iteration 13101/30001... loss 0.0011331322602927685... accuracy 1.0...\n",
      "iteration 13201/30001... loss 0.0013726879842579365... accuracy 1.0...\n",
      "iteration 13301/30001... loss 0.0001379334571538493... accuracy 1.0...\n",
      "iteration 13401/30001... loss 0.0005250766407698393... accuracy 1.0...\n",
      "iteration 13501/30001... loss 0.0003751102776732296... accuracy 1.0...\n",
      "iteration 13601/30001... loss 0.0004550288140308112... accuracy 1.0...\n",
      "iteration 13701/30001... loss 0.0008083591819740832... accuracy 1.0...\n",
      "iteration 13801/30001... loss 0.0013783365720883012... accuracy 1.0...\n",
      "iteration 13901/30001... loss 2.7137684810440987e-05... accuracy 1.0...\n",
      "iteration 14001/30001... loss 0.0007753846584819257... accuracy 1.0...\n",
      "iteration 14101/30001... loss 0.004033341538161039... accuracy 1.0...\n",
      "iteration 14201/30001... loss 0.003238621400669217... accuracy 1.0...\n",
      "iteration 14301/30001... loss 0.0023197217378765345... accuracy 1.0...\n",
      "iteration 14401/30001... loss 0.0281937625259161... accuracy 1.0...\n",
      "iteration 14501/30001... loss 0.0003613026055973023... accuracy 1.0...\n",
      "iteration 14601/30001... loss 0.0009609773405827582... accuracy 1.0...\n",
      "iteration 14701/30001... loss 0.0011403824901208282... accuracy 1.0...\n",
      "iteration 14801/30001... loss 0.0010215400252491236... accuracy 1.0...\n",
      "iteration 14901/30001... loss 0.0025294567458331585... accuracy 1.0...\n",
      "iteration 15001/30001... loss 0.0008473559864796698... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-15000\n",
      "iteration 15101/30001... loss 0.0005287113599479198... accuracy 1.0...\n",
      "iteration 15201/30001... loss 0.01281620655208826... accuracy 1.0...\n",
      "iteration 15301/30001... loss 0.0005662703770212829... accuracy 1.0...\n",
      "iteration 15401/30001... loss 0.0004845948133151978... accuracy 1.0...\n",
      "iteration 15501/30001... loss 0.0012837155954912305... accuracy 1.0...\n",
      "iteration 15601/30001... loss 0.003210430731996894... accuracy 1.0...\n",
      "iteration 15701/30001... loss 0.0003619719936978072... accuracy 1.0...\n",
      "iteration 15801/30001... loss 0.0003212129231542349... accuracy 1.0...\n",
      "iteration 15901/30001... loss 0.0008085209410637617... accuracy 1.0...\n",
      "iteration 16001/30001... loss 0.00160206516738981... accuracy 1.0...\n",
      "iteration 16101/30001... loss 0.0005965172895230353... accuracy 1.0...\n",
      "iteration 16201/30001... loss 0.0014003549003973603... accuracy 1.0...\n",
      "iteration 16301/30001... loss 0.0013484624214470387... accuracy 1.0...\n",
      "iteration 16401/30001... loss 0.0004645820299629122... accuracy 1.0...\n",
      "iteration 16501/30001... loss 0.00011549672490218654... accuracy 1.0...\n",
      "iteration 16601/30001... loss 0.00017607526388019323... accuracy 1.0...\n",
      "iteration 16701/30001... loss 0.0034511738922446966... accuracy 1.0...\n",
      "iteration 16801/30001... loss 1.364911349810427e-05... accuracy 1.0...\n",
      "iteration 16901/30001... loss 0.07215294986963272... accuracy 0.9583333134651184...\n",
      "iteration 17001/30001... loss 0.0076191783882677555... accuracy 1.0...\n",
      "iteration 17101/30001... loss 0.0016095153987407684... accuracy 1.0...\n",
      "iteration 17201/30001... loss 0.0009472884703427553... accuracy 1.0...\n",
      "iteration 17301/30001... loss 0.0013347292551770806... accuracy 1.0...\n",
      "iteration 17401/30001... loss 0.16095463931560516... accuracy 0.9583333134651184...\n",
      "iteration 17501/30001... loss 0.0027392676565796137... accuracy 1.0...\n",
      "iteration 17601/30001... loss 0.00043858899152837694... accuracy 1.0...\n",
      "iteration 17701/30001... loss 0.00842480082064867... accuracy 1.0...\n",
      "iteration 17801/30001... loss 0.0012128486996516585... accuracy 1.0...\n",
      "iteration 17901/30001... loss 0.001846515922807157... accuracy 1.0...\n",
      "iteration 18001/30001... loss 0.001614522305317223... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-18000\n",
      "iteration 18101/30001... loss 0.0008428934379480779... accuracy 1.0...\n",
      "iteration 18201/30001... loss 0.000946006563026458... accuracy 1.0...\n",
      "iteration 18301/30001... loss 0.0004056828038301319... accuracy 1.0...\n",
      "iteration 18401/30001... loss 0.0005303426296450198... accuracy 1.0...\n",
      "iteration 18501/30001... loss 0.000905509281437844... accuracy 1.0...\n",
      "iteration 18601/30001... loss 0.00017462590767536312... accuracy 1.0...\n",
      "iteration 18701/30001... loss 0.00026749048265628517... accuracy 1.0...\n",
      "iteration 18801/30001... loss 0.00023509458696935326... accuracy 1.0...\n",
      "iteration 18901/30001... loss 0.00018512427050154656... accuracy 1.0...\n",
      "iteration 19001/30001... loss 9.906502236844972e-05... accuracy 1.0...\n",
      "iteration 19101/30001... loss 0.005266727413982153... accuracy 1.0...\n",
      "iteration 19201/30001... loss 1.8759963495540433e-05... accuracy 1.0...\n",
      "iteration 19301/30001... loss 4.4400334445526823e-05... accuracy 1.0...\n",
      "iteration 19401/30001... loss 0.00026941587566398084... accuracy 1.0...\n",
      "iteration 19501/30001... loss 4.3185445974813774e-05... accuracy 1.0...\n",
      "iteration 19601/30001... loss 6.21002764091827e-05... accuracy 1.0...\n",
      "iteration 19701/30001... loss 7.619373718625866e-06... accuracy 1.0...\n",
      "iteration 19801/30001... loss 3.40762926498428e-05... accuracy 1.0...\n",
      "iteration 19901/30001... loss 1.6683925423421897e-05... accuracy 1.0...\n",
      "iteration 20001/30001... loss 3.022705095645506e-05... accuracy 1.0...\n",
      "iteration 20101/30001... loss 1.5446126781171188e-05... accuracy 1.0...\n",
      "iteration 20201/30001... loss 5.2883042371831834e-05... accuracy 1.0...\n",
      "iteration 20301/30001... loss 2.287735514983069e-05... accuracy 1.0...\n",
      "iteration 20401/30001... loss 0.00015303930558729917... accuracy 1.0...\n",
      "iteration 20501/30001... loss 9.239238715963438e-05... accuracy 1.0...\n",
      "iteration 20601/30001... loss 6.978527380852029e-06... accuracy 1.0...\n",
      "iteration 20701/30001... loss 4.7989218728616834e-05... accuracy 1.0...\n",
      "iteration 20801/30001... loss 0.013336542062461376... accuracy 1.0...\n",
      "iteration 20901/30001... loss 0.021504545584321022... accuracy 1.0...\n",
      "iteration 21001/30001... loss 0.0009092561085708439... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-21000\n",
      "iteration 21101/30001... loss 0.007704488933086395... accuracy 1.0...\n",
      "iteration 21201/30001... loss 0.0003741215041372925... accuracy 1.0...\n",
      "iteration 21301/30001... loss 0.0018732165917754173... accuracy 1.0...\n",
      "iteration 21401/30001... loss 0.008299269713461399... accuracy 1.0...\n",
      "iteration 21501/30001... loss 0.00038031875737942755... accuracy 1.0...\n",
      "iteration 21601/30001... loss 0.003622068092226982... accuracy 1.0...\n",
      "iteration 21701/30001... loss 0.0008782996446825564... accuracy 1.0...\n",
      "iteration 21801/30001... loss 0.0017802476650103927... accuracy 1.0...\n",
      "iteration 21901/30001... loss 0.002589549170807004... accuracy 1.0...\n",
      "iteration 22001/30001... loss 0.0013774653198197484... accuracy 1.0...\n",
      "iteration 22101/30001... loss 0.002249333309009671... accuracy 1.0...\n",
      "iteration 22201/30001... loss 0.00024647984537295997... accuracy 1.0...\n",
      "iteration 22301/30001... loss 3.752368502318859e-05... accuracy 1.0...\n",
      "iteration 22401/30001... loss 0.00012238818453624845... accuracy 1.0...\n",
      "iteration 22501/30001... loss 0.00016863377823028713... accuracy 1.0...\n",
      "iteration 22601/30001... loss 3.2925341656664386e-05... accuracy 1.0...\n",
      "iteration 22701/30001... loss 0.0004585317801684141... accuracy 1.0...\n",
      "iteration 22801/30001... loss 0.00012956185673829168... accuracy 1.0...\n",
      "iteration 22901/30001... loss 0.0010459377663210034... accuracy 1.0...\n",
      "iteration 23001/30001... loss 2.9516741051338613e-05... accuracy 1.0...\n",
      "iteration 23101/30001... loss 9.89713953458704e-05... accuracy 1.0...\n",
      "iteration 23201/30001... loss 0.0009256892371922731... accuracy 1.0...\n",
      "iteration 23301/30001... loss 0.05448978766798973... accuracy 0.9583333134651184...\n",
      "iteration 23401/30001... loss 6.362712156260386e-06... accuracy 1.0...\n",
      "iteration 23501/30001... loss 2.1737128918175586e-05... accuracy 1.0...\n",
      "iteration 23601/30001... loss 1.879718001873698e-05... accuracy 1.0...\n",
      "iteration 23701/30001... loss 3.920327435480431e-05... accuracy 1.0...\n",
      "iteration 23801/30001... loss 2.913798925874289e-05... accuracy 1.0...\n",
      "iteration 23901/30001... loss 2.0799068806809373e-05... accuracy 1.0...\n",
      "iteration 24001/30001... loss 0.0001634687650948763... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-24000\n",
      "iteration 24101/30001... loss 7.630528853042051e-05... accuracy 1.0...\n",
      "iteration 24201/30001... loss 5.6481239880668e-05... accuracy 1.0...\n",
      "iteration 24301/30001... loss 7.416662265313789e-05... accuracy 1.0...\n",
      "iteration 24401/30001... loss 1.8242435544379987e-05... accuracy 1.0...\n",
      "iteration 24501/30001... loss 1.9917204554076307e-05... accuracy 1.0...\n",
      "iteration 24601/30001... loss 0.00022230639297049493... accuracy 1.0...\n",
      "iteration 24701/30001... loss 2.700942241062876e-05... accuracy 1.0...\n",
      "iteration 24801/30001... loss 5.2816118113696575e-05... accuracy 1.0...\n",
      "iteration 24901/30001... loss 0.02396741695702076... accuracy 1.0...\n",
      "iteration 25001/30001... loss 0.004927737172693014... accuracy 1.0...\n",
      "iteration 25101/30001... loss 0.009852387942373753... accuracy 1.0...\n",
      "iteration 25201/30001... loss 0.002638069912791252... accuracy 1.0...\n",
      "iteration 25301/30001... loss 0.0007855999865569174... accuracy 1.0...\n",
      "iteration 25401/30001... loss 0.0007191068143583834... accuracy 1.0...\n",
      "iteration 25501/30001... loss 0.0007161959656514227... accuracy 1.0...\n",
      "iteration 25601/30001... loss 0.0003759207611437887... accuracy 1.0...\n",
      "iteration 25701/30001... loss 0.0016274225199595094... accuracy 1.0...\n",
      "iteration 25801/30001... loss 0.001631090766750276... accuracy 1.0...\n",
      "iteration 25901/30001... loss 0.00018262979574501514... accuracy 1.0...\n",
      "iteration 26001/30001... loss 0.0007669001934118569... accuracy 1.0...\n",
      "iteration 26101/30001... loss 0.00046612360165454447... accuracy 1.0...\n",
      "iteration 26201/30001... loss 0.0026317397132515907... accuracy 1.0...\n",
      "iteration 26301/30001... loss 0.0004601303080562502... accuracy 1.0...\n",
      "iteration 26401/30001... loss 7.966390694491565e-05... accuracy 1.0...\n",
      "iteration 26501/30001... loss 8.716678712517023e-05... accuracy 1.0...\n",
      "iteration 26601/30001... loss 0.0007112468592822552... accuracy 1.0...\n",
      "iteration 26701/30001... loss 5.5120341130532324e-05... accuracy 1.0...\n",
      "iteration 26801/30001... loss 1.4806457329541445e-05... accuracy 1.0...\n",
      "iteration 26901/30001... loss 2.6834541131393053e-05... accuracy 1.0...\n",
      "iteration 27001/30001... loss 8.54709287523292e-05... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-27000\n",
      "iteration 27101/30001... loss 0.0006258701905608177... accuracy 1.0...\n",
      "iteration 27201/30001... loss 3.500848833937198e-05... accuracy 1.0...\n",
      "iteration 27301/30001... loss 0.00047969326260499656... accuracy 1.0...\n",
      "iteration 27401/30001... loss 0.0030345532577484846... accuracy 1.0...\n",
      "iteration 27501/30001... loss 1.9648208763101138e-05... accuracy 1.0...\n",
      "iteration 27601/30001... loss 0.00015213365259114653... accuracy 1.0...\n",
      "iteration 27701/30001... loss 8.006743883015588e-06... accuracy 1.0...\n",
      "iteration 27801/30001... loss 6.33285299045383e-06... accuracy 1.0...\n",
      "iteration 27901/30001... loss 2.31541689572623e-05... accuracy 1.0...\n",
      "iteration 28001/30001... loss 6.049778221495217e-06... accuracy 1.0...\n",
      "iteration 28101/30001... loss 0.0007986745913513005... accuracy 1.0...\n",
      "iteration 28201/30001... loss 4.98548433824908e-05... accuracy 1.0...\n",
      "iteration 28301/30001... loss 2.1176199879846536e-05... accuracy 1.0...\n",
      "iteration 28401/30001... loss 3.7967962271068245e-05... accuracy 1.0...\n",
      "iteration 28501/30001... loss 3.725256419784273e-06... accuracy 1.0...\n",
      "iteration 28601/30001... loss 1.1711902516253758e-05... accuracy 1.0...\n",
      "iteration 28701/30001... loss 0.00013240145926829427... accuracy 1.0...\n",
      "iteration 28801/30001... loss 3.8121612305985764e-05... accuracy 1.0...\n",
      "iteration 28901/30001... loss 0.0001702740992186591... accuracy 1.0...\n",
      "iteration 29001/30001... loss 4.066961628268473e-05... accuracy 1.0...\n",
      "iteration 29101/30001... loss 3.880961230606772e-05... accuracy 1.0...\n",
      "iteration 29201/30001... loss 4.872859062743373e-05... accuracy 1.0...\n",
      "iteration 29301/30001... loss 1.4731893315911293e-05... accuracy 1.0...\n",
      "iteration 29401/30001... loss 2.6474201604287373e-06... accuracy 1.0...\n",
      "iteration 29501/30001... loss 5.463634806801565e-06... accuracy 1.0...\n",
      "iteration 29601/30001... loss 1.929475911310874e-05... accuracy 1.0...\n",
      "iteration 29701/30001... loss 3.0596736451116158e-06... accuracy 1.0...\n",
      "iteration 29801/30001... loss 1.3609261259261984e-05... accuracy 1.0...\n",
      "iteration 29901/30001... loss 1.6291895690301317e-06... accuracy 1.0...\n",
      "iteration 30001/30001... loss 1.4716956684424076e-05... accuracy 1.0...\n",
      "saved to text2_divide_models/pretrained_lstm.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "#text_section\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "\n",
    "ids_real_text2_train = np.load('data/idsMatrix_real_text2_train.npy')\n",
    "ids_fake_text2_train = np.load('data/idsMatrix_fake_text2_train.npy')\n",
    "\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, text_maxSeqLength])\n",
    "    #一半取正标签\n",
    "    #for i in range(int(batchSize/2)):\n",
    "    #    num = randint(1,len(cleaned_fake_text1_train)-1)\n",
    "    #    labels.append([1,0])\n",
    "    #    arr[i] = ids_fake_text1_train[num-1:num]\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_fake_text2_train)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_text2_train[num-1:num]\n",
    "    #一半取负标签\n",
    "    #for i in range(int(batchSize/2)):\n",
    "    #    num = randint(1,len(cleaned_real_text1_train)-1)\n",
    "    #    labels.append([0,1])\n",
    "    #    arr[int(batchSize/2)+i] = ids_real_text1_train[num-1:num]\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_real_text2_train)-1)\n",
    "        labels.append([0,1])\n",
    "        arr[int(batchSize/2)+i] = ids_real_text2_train[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "\n",
    "batchSize = 24\n",
    "lstmUnits = 256\n",
    "numClasses = 2\n",
    "iterations = 30001\n",
    "text_maxSeqLength = 200\n",
    "numDimensions = 50 \n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, text_maxSeqLength])\n",
    "\n",
    "data = tf.Variable(tf.zeros([batchSize, text_maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "#取最终的结果值\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(1)\n",
    "for i in range(iterations):\n",
    "    #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels}) \n",
    "    if i==0:\n",
    "        print(2)\n",
    "    if (i % 100 == 0 and i != 0):\n",
    "        loss_ = sess.run(loss, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        accuracy_ = sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        \n",
    "        \n",
    "        print(\"iteration {}/{}...\".format(i+1, iterations),\n",
    "              \"loss {}...\".format(loss_),\n",
    "              \"accuracy {}...\".format(accuracy_))\n",
    "    #Save the network every 10,000 training iterations\n",
    "    if (i % 3000 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"text2_divide_models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1001/30001... loss 0.35640695691108704... accuracy 0.7916666865348816...\n",
      "iteration 2001/30001... loss 0.24514137208461761... accuracy 0.875...\n",
      "iteration 3001/30001... loss 0.011979843489825726... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-3000\n",
      "iteration 4001/30001... loss 0.013131335377693176... accuracy 1.0...\n",
      "iteration 5001/30001... loss 0.011537726037204266... accuracy 1.0...\n",
      "iteration 6001/30001... loss 0.004350307863205671... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-6000\n",
      "iteration 7001/30001... loss 0.008152960799634457... accuracy 1.0...\n",
      "iteration 8001/30001... loss 0.004914321005344391... accuracy 1.0...\n",
      "iteration 9001/30001... loss 0.006077875848859549... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-9000\n",
      "iteration 10001/30001... loss 4.351990355644375e-05... accuracy 1.0...\n",
      "iteration 11001/30001... loss 1.8049600839731283e-05... accuracy 1.0...\n",
      "iteration 12001/30001... loss 0.02128800004720688... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-12000\n",
      "iteration 13001/30001... loss 0.0027707889676094055... accuracy 1.0...\n",
      "iteration 14001/30001... loss 3.681728048832156e-05... accuracy 1.0...\n",
      "iteration 15001/30001... loss 1.251153207704192e-05... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-15000\n",
      "iteration 16001/30001... loss 6.6805168899009004e-06... accuracy 1.0...\n",
      "iteration 17001/30001... loss 1.221889874614135e-06... accuracy 1.0...\n",
      "iteration 18001/30001... loss 5.076125489722472e-06... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-18000\n",
      "iteration 19001/30001... loss 1.1026777428924106e-06... accuracy 1.0...\n",
      "iteration 20001/30001... loss 5.145777322468348e-06... accuracy 1.0...\n",
      "iteration 21001/30001... loss 1.0927516314040986e-07... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-21000\n",
      "iteration 22001/30001... loss 1.1722141834979993e-06... accuracy 1.0...\n",
      "iteration 23001/30001... loss 5.960463411724959e-08... accuracy 1.0...\n",
      "iteration 24001/30001... loss 1.9868211964535476e-08... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-24000\n",
      "iteration 25001/30001... loss 2.930551943336468e-07... accuracy 1.0...\n",
      "iteration 26001/30001... loss 2.5331937081318756e-07... accuracy 1.0...\n",
      "iteration 27001/30001... loss 3.476937138202629e-08... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-27000\n",
      "iteration 28001/30001... loss 4.967053435223079e-09... accuracy 1.0...\n",
      "iteration 29001/30001... loss 4.967053435223079e-09... accuracy 1.0...\n",
      "iteration 30001/30001... loss 0.0... accuracy 1.0...\n",
      "saved to title_models/pretrained_lstm.ckpt-30000\n"
     ]
    }
   ],
   "source": [
    "'''#title_section\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "\n",
    "ids_real_title_train = np.load('data/idsMatrix_real_title_train.npy')\n",
    "ids_fake_title_train = np.load('data/idsMatrix_fake_title_train.npy')\n",
    "\n",
    "\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, title_maxSeqLength])\n",
    "    #一半取正标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_fake_title_train)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_title_train[num-1:num]\n",
    "    #一半取负标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_real_title_train)-1)\n",
    "        labels.append([0,1])\n",
    "        arr[int(batchSize/2)+i] = ids_real_title_train[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "\n",
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "iterations = 30001\n",
    "title_maxSeqLength = 20\n",
    "numDimensions = 50 #Dimensions for each word vector\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, title_maxSeqLength])\n",
    "\n",
    "data = tf.Variable(tf.zeros([batchSize, title_maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "#取最终的结果值\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(iterations):\n",
    "    #Next Batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch();\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels}) \n",
    "    \n",
    "    if (i % 1000 == 0 and i != 0):\n",
    "        loss_ = sess.run(loss, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        accuracy_ = sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        \n",
    "        print(\"iteration {}/{}...\".format(i+1, iterations),\n",
    "              \"loss {}...\".format(loss_),\n",
    "              \"accuracy {}...\".format(accuracy_))    \n",
    "    #Save the network every 10,000 training iterations\n",
    "    if (i % 3000 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"title_models/pretrained_lstm.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general acc:\n",
      "89.3749998808\n",
      "fake news acc:\n",
      "86.4166666269\n",
      "real news acc:\n",
      "91.6249998771\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ids_real_text1_testst = np.load('data/idsMatrix_real_text1_test.npy')\n",
    "ids_fake_text1_test = np.load('data/idsMatrix_fake_text1_test.npy')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('text_divide_models'))\n",
    "\n",
    "from random import randint\n",
    "iterations = 100\n",
    "\n",
    "print(\"general acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, text1_maxSeqLength])\n",
    "    #一半取正标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_fake_text1_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_text1_test[num-1:num]\n",
    "    #一半取负标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_real_text1_test)-1)\n",
    "        labels.append([0,1])\n",
    "        arr[int(batchSize/2)+i] = ids_real_text1_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(acc_sum/100)\n",
    "\n",
    "print(\"fake news acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, text1_maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,len(cleaned_fake_text1_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_text1_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(acc_sum/100)\n",
    "\n",
    "\n",
    "print(\"real news acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, text1_maxSeqLength])\n",
    "    \n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,len(cleaned_real_text1_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_real_text1_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(100-acc_sum/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text2_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text2_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general acc:\n",
      "83.3333336115\n",
      "fake news acc:\n",
      "83.5416667461\n",
      "real news acc:\n",
      "85.4583332352\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ids_real_text2_testst = np.load('data/idsMatrix_real_text2_test.npy')\n",
    "ids_fake_text2_test = np.load('data/idsMatrix_fake_text2_test.npy')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('text2_divide_models'))\n",
    "\n",
    "from random import randint\n",
    "iterations = 100\n",
    "\n",
    "print(\"general acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, text2_maxSeqLength])\n",
    "    #一半取正标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_fake_text2_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_text2_test[num-1:num]\n",
    "    #一半取负标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_real_text2_test)-1)\n",
    "        labels.append([0,1])\n",
    "        arr[int(batchSize/2)+i] = ids_real_text2_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(acc_sum/100)\n",
    "\n",
    "print(\"fake news acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, text2_maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,len(cleaned_fake_text2_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_text2_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(acc_sum/100)\n",
    "\n",
    "\n",
    "print(\"real news acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, text2_maxSeqLength])\n",
    "    \n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,len(cleaned_real_text2_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_real_text2_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(100-acc_sum/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from title_models\\pretrained_lstm.ckpt-18000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from title_models\\pretrained_lstm.ckpt-18000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general acc:\n",
      "81.4166667461\n",
      "fake news acc:\n",
      "79.9583331943\n",
      "real news acc:\n",
      "79.666666761\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ids_real_title_test = np.load('data/idsMatrix_real_title_test.npy')\n",
    "ids_fake_title_test = np.load('data/idsMatrix_fake_title_test.npy')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('title_models'))\n",
    "\n",
    "from random import randint\n",
    "iterations = 100\n",
    "\n",
    "print(\"general acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, title_maxSeqLength])\n",
    "    #一半取正标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_fake_title_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_title_test[num-1:num]\n",
    "    #一半取负标签\n",
    "    for i in range(int(batchSize/2)):\n",
    "        num = randint(1,len(cleaned_real_title_test)-1)\n",
    "        labels.append([0,1])\n",
    "        arr[int(batchSize/2)+i] = ids_real_title_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(acc_sum/100)\n",
    "\n",
    "print(\"fake news acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, title_maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,len(cleaned_fake_title_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_title_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(acc_sum/100)\n",
    "\n",
    "\n",
    "print(\"real news acc:\")\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, title_maxSeqLength])\n",
    "    \n",
    "    for i in range(batchSize):\n",
    "        num = randint(1,len(cleaned_real_title_test)-1)\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_real_title_test[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "acc_sum=0\n",
    "for i in range(iterations):\n",
    "    nextBatch, nextBatchLabels = getTestBatch();\n",
    "    temp=sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels}) * 100\n",
    "    #print(\"Accuracy for this batch:\", (temp))\n",
    "    acc_sum+=temp\n",
    "\n",
    "print(100-acc_sum/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.91503334 -5.44351053  3.71424866 ..., -3.38267684  1.2317214\n",
      " -2.79714131]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8589743589743589"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxSeqLength=200\n",
    "\n",
    "ids_real_text1_test = np.load('data/idsMatrix_real_text1_test.npy')\n",
    "ids_fake_text1_test = np.load('data/idsMatrix_fake_text1_test.npy')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('text_divide_models'))\n",
    "\n",
    "predict_fake_text1=[]\n",
    "def getTestBatch(turn):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_text1_test[turn*batchSize+i:turn*batchSize+i+1]\n",
    "    return arr, labels\n",
    "for i in range(int(ids_fake_text1_test.shape[0]/batchSize)):\n",
    "    nextBatch, nextBatchLabels = getTestBatch(i);\n",
    "    temp=sess.run(prediction, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    predict_fake_text1=np.append(predict_fake_text1,[temp])\n",
    "print(predict_fake_text1)\n",
    "\n",
    "label_fake_text1=[]\n",
    "for i in range(int(len(predict_fake_text1)/2)):\n",
    "    if predict_fake_text1[2*i]>predict_fake_text1[2*i+1]:\n",
    "        label_fake_text1.append(1)\n",
    "    else:\n",
    "        label_fake_text1.append(0)\n",
    "sumup=0\n",
    "for i in label_fake_text1:\n",
    "    sumup+=i\n",
    "sumup/len(label_fake_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text2_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text2_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.1370697  -5.38258791 -4.30865335 ...,  0.56275803 -0.15881418\n",
      " -0.81727338]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8247863247863247"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 256\n",
    "numClasses = 2\n",
    "text_maxSeqLength = 200\n",
    "numDimensions = 50 \n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, text_maxSeqLength])\n",
    "\n",
    "data = tf.Variable(tf.zeros([batchSize, text_maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "#取最终的结果值\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "\n",
    "maxSeqLength=200\n",
    "\n",
    "ids_real_text2_test = np.load('data/idsMatrix_real_text2_test.npy')\n",
    "ids_fake_text2_test = np.load('data/idsMatrix_fake_text2_test.npy')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('text2_divide_models'))\n",
    "\n",
    "predict_fake_text2=[]\n",
    "def getTestBatch(turn):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_text2_test[turn*batchSize+i:turn*batchSize+i+1]\n",
    "    return arr, labels\n",
    "for i in range(int(ids_fake_text2_test.shape[0]/batchSize)):\n",
    "    nextBatch, nextBatchLabels = getTestBatch(i);\n",
    "    temp=sess.run(prediction, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    predict_fake_text2=np.append(predict_fake_text2,[temp])\n",
    "print(predict_fake_text2)\n",
    "\n",
    "label_fake_text2=[]\n",
    "for i in range(int(len(predict_fake_text2)/2)):\n",
    "    if predict_fake_text2[2*i]>predict_fake_text2[2*i+1]:\n",
    "        label_fake_text2.append(1)\n",
    "    else:\n",
    "        label_fake_text2.append(0)\n",
    "sumup=0\n",
    "for i in label_fake_text2:\n",
    "    sumup+=i\n",
    "sumup/len(label_fake_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from title_models\\pretrained_lstm.ckpt-18000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from title_models\\pretrained_lstm.ckpt-18000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.1370697  -5.38258791 -4.30865335 ...,  1.79240322  5.35778093\n",
      " -8.82487297]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.821875"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "title_maxSeqLength = 20\n",
    "numDimensions = 50 #Dimensions for each word vector\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, title_maxSeqLength])\n",
    "\n",
    "data = tf.Variable(tf.zeros([batchSize, title_maxSeqLength, numDimensions]),dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n",
    "\n",
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "#取最终的结果值\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)\n",
    "\n",
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('title_models'))\n",
    "\n",
    "maxSeqLength=20\n",
    "\n",
    "ids_real_title_test = np.load('data/idsMatrix_real_title_test.npy')\n",
    "ids_fake_title_test = np.load('data/idsMatrix_fake_title_test.npy')\n",
    "\n",
    "\n",
    "predict_fake_title=[]\n",
    "def getTestBatch(turn):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_fake_title_test[turn*batchSize+i:turn*batchSize+i+1]\n",
    "    return arr, labels\n",
    "for i in range(int(ids_fake_title_test.shape[0]/batchSize)):\n",
    "    nextBatch, nextBatchLabels = getTestBatch(i);\n",
    "    temp=sess.run(prediction, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    predict_fake_title=np.append(predict_fake_text2,[temp])\n",
    "print(predict_fake_title)\n",
    "\n",
    "label_fake_title=[]\n",
    "for i in range(int(len(predict_fake_title)/2)):\n",
    "    if predict_fake_title[2*i]>predict_fake_title[2*i+1]:\n",
    "        label_fake_title.append(1)\n",
    "    else:\n",
    "        label_fake_title.append(0)\n",
    "sumup=0\n",
    "for i in label_fake_title:\n",
    "    sumup+=i\n",
    "sumup/len(label_fake_title)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9123931623931624"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fake_text=[]\n",
    "for i in range(len(predict_fake_text1)):\n",
    "    predict_fake_text.append(predict_fake_text1[i]*1.5+predict_fake_text2[i])\n",
    "\n",
    "label_fake_text=[]\n",
    "for i in range(int(len(predict_fake_text)/2)):\n",
    "    if predict_fake_text[2*i]>predict_fake_text[2*i+1]:\n",
    "        label_fake_text.append(1)\n",
    "    else:\n",
    "        label_fake_text.append(0)\n",
    "sumup=0\n",
    "for i in label_fake_text:\n",
    "    sumup+=i\n",
    "sumup/len(label_fake_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.67671537   7.55834341   0.0983786  ...,  12.14595318  -6.51120758\n",
      "   5.89150953]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9262820512820513"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxSeqLength=200\n",
    "\n",
    "ids_real_text1_testst = np.load('data/idsMatrix_real_text1_test.npy')\n",
    "ids_fake_text1_test = np.load('data/idsMatrix_fake_text1_test.npy')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('text_divide_models'))\n",
    "\n",
    "predict_real_text1=[]\n",
    "def getTestBatch(turn):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_real_text1_test[turn*batchSize+i:turn*batchSize+i+1]\n",
    "    return arr, labels\n",
    "for i in range(int(ids_real_text1_test.shape[0]/batchSize)):\n",
    "    nextBatch, nextBatchLabels = getTestBatch(i);\n",
    "    temp=sess.run(prediction, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    predict_real_text1=np.append(predict_real_text1,[temp])\n",
    "print(predict_real_text1)\n",
    "\n",
    "label_real_text1=[]\n",
    "for i in range(int(len(predict_real_text1)/2)):\n",
    "    if predict_real_text1[2*i]>predict_real_text1[2*i+1]:\n",
    "        label_real_text1.append(0)\n",
    "    else:\n",
    "        label_real_text1.append(1)\n",
    "sumup=0\n",
    "for i in label_real_text1:\n",
    "    sumup+=i\n",
    "sumup/len(label_real_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text2_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from text2_divide_models\\pretrained_lstm.ckpt-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -5.16169643   5.00713873  -6.24155951 ...,   8.05907536 -11.8684454\n",
      "  14.17006683]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8504273504273504"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxSeqLength=200\n",
    "\n",
    "ids_real_text2_testst = np.load('data/idsMatrix_real_text2_test.npy')\n",
    "ids_fake_text2_test = np.load('data/idsMatrix_fake_text2_test.npy')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('text2_divide_models'))\n",
    "\n",
    "predict_real_text2=[]\n",
    "def getTestBatch(turn):\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        labels.append([1,0])\n",
    "        arr[i] = ids_real_text2_test[turn*batchSize+i:turn*batchSize+i+1]\n",
    "    return arr, labels\n",
    "for i in range(int(ids_real_text2_test.shape[0]/batchSize)):\n",
    "    nextBatch, nextBatchLabels = getTestBatch(i);\n",
    "    temp=sess.run(prediction, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    predict_real_text2=np.append(predict_real_text2,[temp])\n",
    "print(predict_real_text2)\n",
    "\n",
    "label_real_text2=[]\n",
    "for i in range(int(len(predict_real_text2)/2)):\n",
    "    if predict_real_text2[2*i]>predict_real_text2[2*i+1]:\n",
    "        label_real_text2.append(0)\n",
    "    else:\n",
    "        label_real_text2.append(1)\n",
    "sumup=0\n",
    "for i in label_real_text2:\n",
    "    sumup+=i\n",
    "sumup/len(label_real_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9262820512820513\n",
      "0.9113247863247863\n",
      "0.9188034188034189\n"
     ]
    }
   ],
   "source": [
    "predict_real_text=[]\n",
    "for i in range(len(predict_real_text1)):\n",
    "    predict_real_text.append(predict_real_text1[i]*1.6+predict_real_text2[i])\n",
    "\n",
    "label_real_text=[]\n",
    "for i in range(int(len(predict_real_text)/2)):\n",
    "    if predict_real_text[2*i]>predict_real_text[2*i+1]:\n",
    "        label_real_text.append(0)\n",
    "    else:\n",
    "        label_real_text.append(1)\n",
    "sumup1=0\n",
    "for i in label_real_text:\n",
    "    sumup1+=i\n",
    "print(sumup1/len(label_real_text))\n",
    "\n",
    "predict_fake_text=[]\n",
    "for i in range(len(predict_fake_text1)):\n",
    "    predict_fake_text.append(predict_fake_text1[i]*1.6+predict_fake_text2[i])\n",
    "\n",
    "label_fake_text=[]\n",
    "for i in range(int(len(predict_fake_text)/2)):\n",
    "    if predict_fake_text[2*i]>predict_fake_text[2*i+1]:\n",
    "        label_fake_text.append(1)\n",
    "    else:\n",
    "        label_fake_text.append(0)\n",
    "sumup2=0\n",
    "for i in label_fake_text:\n",
    "    sumup2+=i\n",
    "print(sumup2/len(label_fake_text))\n",
    "print((sumup2/len(label_fake_text)+sumup1/len(label_real_text))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
